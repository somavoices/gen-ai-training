{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Session 1.5A: Embeddings Deep Dive ‚Äî The Full Experience\n",
    "\n",
    "**Requires:** `pip install sentence-transformers` (~500MB, includes torch)  \n",
    "**Model:** `all-MiniLM-L6-v2` ‚Äî 22M parameters, 384 dimensions, runs on CPU  \n",
    "**Focus:** Experience CONTEXTUAL embeddings ‚Äî the model reads the whole sentence\n",
    "\n",
    "---\n",
    "\n",
    "## What You Will Experience\n",
    "\n",
    "```\n",
    "Part 1 ‚Üí Install and load a pretrained model ‚Äî understand what's inside\n",
    "Part 2 ‚Üí Word-level embeddings ‚Äî how words encode meaning\n",
    "Part 3 ‚Üí Sentence-level ‚Äî the model reads full context, not just words\n",
    "Part 4 ‚Üí Context-awareness ‚Äî 'bank' gets a DIFFERENT vector per sentence\n",
    "Part 5 ‚Üí Bias ‚Äî pretrained models carry bias from the internet\n",
    "Part 6 ‚Üí Visualize ‚Äî 2D PCA map of your banking sentences\n",
    "Part 7 ‚Üí Dimensions ‚Äî peer inside the 384 numbers\n",
    "Part 8 ‚Üí Compare with Notebook B ‚Äî what contextual models solve\n",
    "```\n",
    "\n",
    "## How this differs from Notebook B (gensim)\n",
    "\n",
    "| | Notebook B (gensim) | Notebook A (this notebook) |\n",
    "|--|--|--|\n",
    "| Model | Word2Vec ‚Äî you train it | all-MiniLM-L6-v2 ‚Äî pretrained |\n",
    "| Training | You see it happen | Already trained on billions of sentences |\n",
    "| Granularity | One vector per WORD | One vector per SENTENCE |\n",
    "| Context | Static ‚Äî 'bank' = one vector | Contextual ‚Äî 'bank' changes by sentence |\n",
    "| Dimensions | 50 | 384 |\n",
    "| Size | ~5MB | ~500MB |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads ~500MB on first run (model weights + torch)\n",
    "# Subsequent runs use the local cache ‚Äî no re-download needed\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Loading model: all-MiniLM-L6-v2\")\n",
    "print(\"First run downloads ~90MB of model weights...\")\n",
    "t0 = time.time()\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"‚úÖ Model ready in {elapsed:.1f}s\")\n",
    "print(f\"   Architecture: 6-layer MiniLM transformer\")\n",
    "print(f\"   Parameters:   22 million\")\n",
    "print(f\"   Output dims:  384 per sentence\")\n",
    "print(f\"   Trained on:   1 billion+ sentence pairs from the internet\")\n",
    "print()\n",
    "print(\"üìå You did NOT train this model ‚Äî it already knows English.\")\n",
    "print(\"   It was trained to make similar sentences have similar vectors.\")\n",
    "print(\"   Your Notebook B model only knew 46 banking sentences you wrote.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: What Is Inside the Model?\n",
    "\n",
    "Before using it, understand what `all-MiniLM-L6-v2` actually is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model architecture\n",
    "print(\"=== Model Architecture ===\")\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# Encode one sentence ‚Äî see the raw output\n",
    "sample = \"AML compliance team monitors suspicious transactions.\"\n",
    "vec = model.encode(sample)\n",
    "\n",
    "print(f\"=== Output for: '{sample}' ===\")\n",
    "print(f\"  Type:       {type(vec)}\")\n",
    "print(f\"  Shape:      {vec.shape}\")\n",
    "print(f\"  Dimensions: {len(vec)}\")\n",
    "print(f\"  Range:      [{vec.min():.4f}, {vec.max():.4f}]\")\n",
    "print(f\"  First 10:   {vec[:10].round(4)}\")\n",
    "print()\n",
    "print(\"üìå 384 numbers represent the MEANING of the entire sentence.\")\n",
    "print(\"   Unlike Word2Vec, this is computed for the whole sentence at once.\")\n",
    "print(\"   The model read every word in context before producing this vector.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What did training look like? (conceptual ‚Äî we can't re-run it)\n",
    "print(\"=== How all-MiniLM-L6-v2 Was Trained (conceptual) ===\")\n",
    "print(\"\"\"\n",
    "Training objective: Contrastive learning on sentence pairs\n",
    "\n",
    "Given pairs like:\n",
    "  SIMILAR:  ('AML detects money laundering', 'Anti-money laundering compliance')\n",
    "  DIFFERENT: ('AML detects money laundering', 'The river bank flooded')\n",
    "\n",
    "The model adjusts weights so that:\n",
    "  encode(similar_A) ‚âà encode(similar_B)   ‚Üí high cosine similarity\n",
    "  encode(different_A) ‚â† encode(different_B) ‚Üí low cosine similarity\n",
    "\n",
    "Dataset: 1 billion+ pairs from NLI datasets, Wikipedia, Reddit, etc.\n",
    "Result:  A model that understands paraphrase, topic, and intent.\n",
    "\n",
    "Compare with your Notebook B model:\n",
    "  Word2Vec: trained on 46 sentences you wrote\n",
    "  MiniLM:   trained on 1 billion sentence pairs\n",
    "  ‚Üí MiniLM generalizes to any English sentence, even ones it never saw.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Word-Level ‚Äî Does It Understand Banking Terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence-transformers encodes sentences, but we can probe single words too\n",
    "# Each word is treated as a one-word sentence\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    \"\"\"Cosine similarity between two numpy vectors.\"\"\"\n",
    "    dot   = float(sum(a * b for a, b in zip(v1, v2)))\n",
    "    norm1 = math.sqrt(sum(a * a for a in v1))\n",
    "    norm2 = math.sqrt(sum(b * b for b in v2))\n",
    "    return dot / (norm1 * norm2) if norm1 and norm2 else 0.0\n",
    "\n",
    "BANKING_WORDS = [\"AML\", \"KYC\", \"BSA\", \"compliance\",\n",
    "                 \"fraud\", \"suspicious\", \"chargeback\",\n",
    "                 \"mortgage\", \"savings\", \"overdraft\",\n",
    "                 \"capital\", \"risk\", \"credit\",\n",
    "                 \"wire\", \"SWIFT\", \"payment\"]\n",
    "\n",
    "# Encode all words\n",
    "word_vecs = {w: model.encode(w) for w in BANKING_WORDS}\n",
    "\n",
    "# Similarity pairs\n",
    "pairs = [\n",
    "    (\"AML\",       \"KYC\",        \"Both compliance programs\"),\n",
    "    (\"AML\",       \"BSA\",        \"Both regulatory requirements\"),\n",
    "    (\"fraud\",     \"suspicious\", \"Related ‚Äî fraud triggers suspicion\"),\n",
    "    (\"mortgage\",  \"credit\",     \"Both lending concepts\"),\n",
    "    (\"wire\",      \"SWIFT\",      \"Wire uses SWIFT network\"),\n",
    "    (\"AML\",       \"mortgage\",   \"Different domains\"),\n",
    "    (\"fraud\",     \"capital\",    \"Very different domains\"),\n",
    "]\n",
    "\n",
    "print(\"=== Word-Level Similarity (pretrained model) ===\")\n",
    "print(f\"{'Word A':<14} {'Word B':<14} {'Similarity':<12} Relationship\")\n",
    "print(\"-\" * 72)\n",
    "for w1, w2, reason in pairs:\n",
    "    sim = cosine_sim(word_vecs[w1], word_vecs[w2])\n",
    "    verdict = \"CLOSE\" if sim > 0.7 else \"RELATED\" if sim > 0.4 else \"DISTANT\"\n",
    "    print(f\"{w1:<14} {w2:<14} {sim:<12.3f} {verdict} ‚Äî {reason}\")\n",
    "\n",
    "print()\n",
    "print(\"üìå The model was NOT trained on your banking corpus.\")\n",
    "print(\"   It knows AML ‚âà KYC because it was trained on billions of sentences\")\n",
    "print(\"   that include compliance literature, regulations, news articles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar words ‚Äî manual nearest-neighbor search\n",
    "def most_similar_words(query_word, word_vecs, top_n=5):\n",
    "    \"\"\"Find top_n most similar words by cosine similarity.\"\"\"\n",
    "    qv = word_vecs[query_word]\n",
    "    scores = [(w, cosine_sim(qv, v)) for w, v in word_vecs.items() if w != query_word]\n",
    "    scores.sort(key=lambda x: -x[1])\n",
    "    return scores[:top_n]\n",
    "\n",
    "print(\"=== Most Similar Words (from our banking vocabulary) ===\")\n",
    "for probe in [\"AML\", \"fraud\", \"mortgage\", \"wire\"]:\n",
    "    print(f\"\\n'{probe}' ‚Üí most similar:\")\n",
    "    for w, s in most_similar_words(probe, word_vecs):\n",
    "        bar = \"‚ñà\" * int(s * 20)\n",
    "        print(f\"  {w:<16} {s:.3f}  {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Sentence-Level ‚Äî The Model Reads Full Context\n",
    "\n",
    "Unlike Notebook B where you averaged word vectors, `sentence-transformers`  \n",
    "reads the **entire sentence at once** through the transformer layers.  \n",
    "Word order, grammar, and sentence structure all influence the output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence similarity ‚Äî same topics should score high\n",
    "BANKING_SENTENCES = [\n",
    "    # Compliance\n",
    "    \"The AML team monitors suspicious transactions for money laundering.\",\n",
    "    \"Compliance analysts review flagged activity reports for BSA violations.\",\n",
    "    \"KYC onboarding requires customers to submit identity documents.\",\n",
    "    # Fraud\n",
    "    \"Fraud detection models flag anomalous card transaction patterns.\",\n",
    "    \"Unauthorized account access triggered an immediate fraud investigation.\",\n",
    "    \"The chargeback process was initiated after the disputed transaction.\",\n",
    "    # Retail\n",
    "    \"Mortgage loan approval depends on the applicant's credit score and income.\",\n",
    "    \"The savings account earns interest on deposited customer funds.\",\n",
    "    \"Overdraft fees are charged when the account balance goes negative.\",\n",
    "    # Capital\n",
    "    \"Basel III requires banks to maintain minimum capital adequacy ratios.\",\n",
    "    \"Credit risk assessment evaluates the borrower's probability of default.\",\n",
    "    \"Liquidity risk management ensures the bank can meet its obligations.\",\n",
    "    # Payments\n",
    "    \"Wire transfers above ten thousand dollars require regulatory reporting.\",\n",
    "    \"The SWIFT network routes international payments between correspondent banks.\",\n",
    "    \"Payment gateway authorization occurs in real time at point of sale.\",\n",
    "]\n",
    "\n",
    "SENTENCE_LABELS = [\n",
    "    \"Compliance\", \"Compliance\", \"Compliance\",\n",
    "    \"Fraud\",      \"Fraud\",      \"Fraud\",\n",
    "    \"Retail\",     \"Retail\",     \"Retail\",\n",
    "    \"Capital\",    \"Capital\",    \"Capital\",\n",
    "    \"Payments\",   \"Payments\",   \"Payments\",\n",
    "]\n",
    "\n",
    "# Encode all sentences in one batch (faster)\n",
    "sentence_vecs = model.encode(BANKING_SENTENCES)\n",
    "print(f\"‚úÖ Encoded {len(BANKING_SENTENCES)} sentences\")\n",
    "print(f\"   Output shape: {sentence_vecs.shape}  (sentences √ó dimensions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence pair similarity ‚Äî same cluster should score high\n",
    "sentence_pairs = [\n",
    "    (0, 1,  \"Compliance A vs Compliance B ‚Äî same topic\"),\n",
    "    (0, 2,  \"Compliance A vs KYC ‚Äî both compliance\"),\n",
    "    (3, 4,  \"Fraud A vs Fraud B ‚Äî same topic\"),\n",
    "    (6, 7,  \"Retail A vs Retail B ‚Äî same topic\"),\n",
    "    (0, 6,  \"Compliance vs Retail ‚Äî different topics\"),\n",
    "    (3, 9,  \"Fraud vs Capital ‚Äî very different\"),\n",
    "    (12, 13, \"Payments A vs Payments B ‚Äî same topic\"),\n",
    "]\n",
    "\n",
    "print(\"=== Sentence-Level Similarity ===\")\n",
    "print(f\"{'Sentence A (truncated)':<42} {'Sentence B (truncated)':<42} {'Sim':>6}  Label\")\n",
    "print(\"-\" * 100)\n",
    "for i, j, label in sentence_pairs:\n",
    "    sim = cosine_sim(sentence_vecs[i], sentence_vecs[j])\n",
    "    a = BANKING_SENTENCES[i][:40]\n",
    "    b = BANKING_SENTENCES[j][:40]\n",
    "    verdict = \"‚úì HIGH\" if sim > 0.6 else \"~ MED\" if sim > 0.35 else \"‚úó LOW\"\n",
    "    print(f\"{a:<42} {b:<42} {sim:>6.3f}  {verdict} ‚Äî {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word order test ‚Äî sentence-transformers DOES consider order\n",
    "# Notebook B's averaging gave IDENTICAL vectors for same words in any order\n",
    "\n",
    "print(\"=== Word Order Test: Does Order Matter? ===\")\n",
    "print(\"(Notebook B: same words ‚Üí identical vectors. Let's see if this model differs.)\")\n",
    "print()\n",
    "\n",
    "order_pairs = [\n",
    "    (\n",
    "        \"The bank approved the loan application.\",\n",
    "        \"The loan application approved the bank.\",\n",
    "        \"Grammatically reversed\"\n",
    "    ),\n",
    "    (\n",
    "        \"The customer reported fraud to the bank.\",\n",
    "        \"The bank reported fraud to the customer.\",\n",
    "        \"Opposite meaning ‚Äî same words\"\n",
    "    ),\n",
    "    (\n",
    "        \"AML controls prevent money laundering.\",\n",
    "        \"Money laundering prevents AML controls.\",\n",
    "        \"Reversed subject/object\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for s1, s2, label in order_pairs:\n",
    "    v1 = model.encode(s1)\n",
    "    v2 = model.encode(s2)\n",
    "    sim = cosine_sim(v1, v2)\n",
    "    print(f\"A: '{s1}'\")\n",
    "    print(f\"B: '{s2}'\")\n",
    "    print(f\"Similarity: {sim:.3f} ‚Äî {label}\")\n",
    "    if sim < 0.95:\n",
    "        print(\"‚úì Vectors DIFFER ‚Äî model respects word order!\")\n",
    "    else:\n",
    "        print(\"‚úó Vectors nearly identical ‚Äî order had little effect here.\")\n",
    "    print()\n",
    "\n",
    "print(\"üìå Compare: in Notebook B, reversed sentences had IDENTICAL vectors.\")\n",
    "print(\"   sentence-transformers encodes word order, grammar, and sentence structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Context-Awareness ‚Äî The Key Advantage\n",
    "\n",
    "In Notebook B, `'bank'` had **one vector** regardless of meaning.  \n",
    "Here, `'bank'` gets a **different vector** in each sentence because  \n",
    "the transformer reads the surrounding words before producing any vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'bank' disambiguation test\n",
    "# Notebook B: 'bank' = ONE vector, confused average of both meanings\n",
    "# This notebook: 'bank' = DIFFERENT vector per context\n",
    "\n",
    "financial_sentences = [\n",
    "    \"The bank approved the mortgage application after reviewing the credit score.\",\n",
    "    \"We opened a savings account at the bank downtown.\",\n",
    "    \"The bank rejected the loan due to insufficient collateral.\",\n",
    "    \"The central bank raised interest rates to control inflation.\",\n",
    "]\n",
    "\n",
    "river_sentences = [\n",
    "    \"The river bank flooded during the heavy rainstorm last night.\",\n",
    "    \"Fishermen sat on the bank waiting for the evening catch.\",\n",
    "    \"Erosion weakened the bank of the river near the bridge.\",\n",
    "    \"The muddy bank was slippery after three days of rain.\",\n",
    "]\n",
    "\n",
    "fin_vecs   = model.encode(financial_sentences)\n",
    "river_vecs = model.encode(river_sentences)\n",
    "\n",
    "# Within-group vs cross-group similarity\n",
    "def avg_sim(vecs_a, vecs_b):\n",
    "    \"\"\"Average cosine similarity between all pairs across two groups.\"\"\"\n",
    "    sims = [cosine_sim(a, b) for a in vecs_a for b in vecs_b]\n",
    "    return sum(sims) / len(sims)\n",
    "\n",
    "def within_sim(vecs):\n",
    "    \"\"\"Average cosine similarity within a group (excluding self).\"\"\"\n",
    "    n = len(vecs)\n",
    "    sims = [cosine_sim(vecs[i], vecs[j]) for i in range(n) for j in range(n) if i != j]\n",
    "    return sum(sims) / len(sims) if sims else 0.0\n",
    "\n",
    "print(\"=== 'bank' disambiguation: Financial vs River ===\")\n",
    "print()\n",
    "print(f\"Within financial sentences:  {within_sim(fin_vecs):.3f}\")\n",
    "print(f\"Within river sentences:      {within_sim(river_vecs):.3f}\")\n",
    "print(f\"Financial vs River (cross):  {avg_sim(fin_vecs, river_vecs):.3f}\")\n",
    "print()\n",
    "print(\"üìå Financial sentences cluster together.\")\n",
    "print(\"   River sentences cluster together.\")\n",
    "print(\"   The two groups are DISTANT despite sharing the word 'bank'.\")\n",
    "print(\"   In Notebook B: 'bank' had ONE confused vector mixing both meanings.\")\n",
    "print(\"   Here: the model reads context ‚Üí produces meaning-appropriate vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concrete pairwise comparison: financial vs river\n",
    "print(\"=== Pairwise: Financial 'bank' vs River 'bank' ===\")\n",
    "print()\n",
    "print(\"Comparing financial sentence 1 to all river sentences:\")\n",
    "s_fin = financial_sentences[0]\n",
    "v_fin = fin_vecs[0]\n",
    "print(f\"  Query: '{s_fin[:70]}...'\")\n",
    "print()\n",
    "for s_riv, v_riv in zip(river_sentences, river_vecs):\n",
    "    sim = cosine_sim(v_fin, v_riv)\n",
    "    print(f\"  {sim:.3f}  '{s_riv[:65]}'\")\n",
    "\n",
    "print()\n",
    "print(\"Comparing financial sentence 1 to other financial sentences:\")\n",
    "for s2, v2 in zip(financial_sentences[1:], fin_vecs[1:]):\n",
    "    sim = cosine_sim(v_fin, v2)\n",
    "    print(f\"  {sim:.3f}  '{s2[:65]}'\")\n",
    "\n",
    "print()\n",
    "print(\"üìå Financial sentences are much more similar to each other\")\n",
    "print(\"   than to river sentences ‚Äî even though all contain 'bank'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Bias ‚Äî Pretrained Models Carry Internet-Scale Bias\n",
    "\n",
    "In Notebook B, you deliberately fed biased sentences.  \n",
    "Here, bias is already present ‚Äî baked in during pretraining on web data.  \n",
    "This is more realistic: production models are pretrained, not trained by you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: are gender-neutral job titles closer to one gender?\n",
    "# Method: compare cosine(job, 'he worked as') vs cosine(job, 'she worked as')\n",
    "\n",
    "MALE_ANCHOR   = \"He works as a\"\n",
    "FEMALE_ANCHOR = \"She works as a\"\n",
    "\n",
    "BANKING_ROLES = [\n",
    "    \"compliance analyst\",\n",
    "    \"risk manager\",\n",
    "    \"loan officer\",\n",
    "    \"fraud investigator\",\n",
    "    \"branch manager\",\n",
    "    \"portfolio manager\",\n",
    "    \"customer service representative\",\n",
    "    \"credit analyst\",\n",
    "    \"treasury analyst\",\n",
    "    \"administrative assistant\",\n",
    "]\n",
    "\n",
    "male_anchor_vec   = model.encode(MALE_ANCHOR)\n",
    "female_anchor_vec = model.encode(FEMALE_ANCHOR)\n",
    "\n",
    "print(\"=== Gender Proximity in Pretrained Model ===\")\n",
    "print(f\"Anchor A: '{MALE_ANCHOR}'\")\n",
    "print(f\"Anchor B: '{FEMALE_ANCHOR}'\")\n",
    "print()\n",
    "print(f\"{'Role':<35} {'Sim(male anchor)':<20} {'Sim(female anchor)':<20} {'Bias direction'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for role in BANKING_ROLES:\n",
    "    role_vec = model.encode(role)\n",
    "    sim_male   = cosine_sim(role_vec, male_anchor_vec)\n",
    "    sim_female = cosine_sim(role_vec, female_anchor_vec)\n",
    "    diff = sim_male - sim_female\n",
    "    direction = f\"‚Üí male   (+{diff:.3f})\" if diff > 0.002 else \\\n",
    "                f\"‚Üí female ({diff:.3f})\" if diff < -0.002 else \\\n",
    "                \"  neutral\"\n",
    "    print(f\"{role:<35} {sim_male:<20.4f} {sim_female:<20.4f} {direction}\")\n",
    "\n",
    "print()\n",
    "print(\"üìå These biases come from web text used in pretraining.\")\n",
    "print(\"   The model did not choose them ‚Äî they reflect historical language patterns.\")\n",
    "print(\"   Regulators (CFPB, EBA) now require bias audits for models used in lending.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second bias test: does the model associate compliance with specific demographics?\n",
    "SENTENCES_TO_TEST = [\n",
    "    # Same compliance scenario, only name differs\n",
    "    \"John Smith was flagged by the AML system for suspicious transactions.\",\n",
    "    \"Maria Garcia was flagged by the AML system for suspicious transactions.\",\n",
    "    \"Wei Zhang was flagged by the AML system for suspicious transactions.\",\n",
    "    \"Ahmed Hassan was flagged by the AML system for suspicious transactions.\",\n",
    "]\n",
    "\n",
    "HIGH_RISK_ANCHOR = \"This person is a high-risk customer requiring enhanced due diligence.\"\n",
    "LOW_RISK_ANCHOR  = \"This person is a low-risk customer with standard verification.\"\n",
    "\n",
    "high_risk_vec = model.encode(HIGH_RISK_ANCHOR)\n",
    "low_risk_vec  = model.encode(LOW_RISK_ANCHOR)\n",
    "test_vecs     = model.encode(SENTENCES_TO_TEST)\n",
    "\n",
    "print(\"=== Name-Based Bias: Same AML Scenario, Different Names ===\")\n",
    "print(f\"High-risk anchor: '{HIGH_RISK_ANCHOR}'\")\n",
    "print(f\"Low-risk anchor:  '{LOW_RISK_ANCHOR}'\")\n",
    "print()\n",
    "print(f\"{'Name':<15} {'Sim(high-risk)':<18} {'Sim(low-risk)':<18} Relative risk score\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "names = [\"John Smith\", \"Maria Garcia\", \"Wei Zhang\", \"Ahmed Hassan\"]\n",
    "for name, vec in zip(names, test_vecs):\n",
    "    sim_high = cosine_sim(vec, high_risk_vec)\n",
    "    sim_low  = cosine_sim(vec, low_risk_vec)\n",
    "    risk_score = sim_high - sim_low\n",
    "    bar = \"‚ñà\" * int(abs(risk_score) * 200)\n",
    "    direction = \"+\" if risk_score > 0 else \"-\"\n",
    "    print(f\"{name:<15} {sim_high:<18.4f} {sim_low:<18.4f} {direction}{abs(risk_score):.4f} {bar}\")\n",
    "\n",
    "print()\n",
    "print(\"üìå If these scores differ materially by name, the model encodes name-based bias.\")\n",
    "print(\"   A fair system should give identical scores ‚Äî same sentence, same risk.\")\n",
    "print(\"   This is the algorithmic fairness problem in AML and credit decisioning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Visualize ‚Äî 2D Map of Banking Sentence Space\n",
    "\n",
    "Reduce 384 dimensions to 2 using PCA to see how sentences cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA from scratch ‚Äî pure Python stdlib, no sklearn\n",
    "import math, random\n",
    "\n",
    "def pca_2d(matrix):\n",
    "    \"\"\"\n",
    "    Reduce NxD matrix to Nx2 using PCA.\n",
    "    Pure Python ‚Äî no numpy, no sklearn.\n",
    "    \"\"\"\n",
    "    n, d = len(matrix), len(matrix[0])\n",
    "\n",
    "    # Center the data\n",
    "    means = [sum(matrix[i][j] for i in range(n)) / n for j in range(d)]\n",
    "    centered = [[matrix[i][j] - means[j] for j in range(d)] for i in range(n)]\n",
    "\n",
    "    def dot(a, b):\n",
    "        return sum(x * y for x, y in zip(a, b))\n",
    "\n",
    "    def mat_vec(M, v):\n",
    "        return [dot(row, v) for row in M]\n",
    "\n",
    "    def normalize(v):\n",
    "        n = math.sqrt(sum(x * x for x in v))\n",
    "        return [x / n for x in v] if n > 0 else v\n",
    "\n",
    "    def subtract_proj(v, u):\n",
    "        p = dot(v, u)\n",
    "        return [v[i] - p * u[i] for i in range(len(v))]\n",
    "\n",
    "    # Covariance matrix C = X^T X / n\n",
    "    C = [[sum(centered[k][i] * centered[k][j] for k in range(n)) / n\n",
    "          for j in range(d)] for i in range(d)]\n",
    "\n",
    "    random.seed(42)\n",
    "    pcs = []\n",
    "    for _ in range(2):\n",
    "        v = normalize([random.gauss(0, 1) for _ in range(d)])\n",
    "        for _ in range(100):\n",
    "            v = normalize(mat_vec(C, v))\n",
    "            for pc in pcs:\n",
    "                v = normalize(subtract_proj(v, pc))\n",
    "        pcs.append(v)\n",
    "\n",
    "    coords = [[dot(row, pcs[0]), dot(row, pcs[1])] for row in centered]\n",
    "    return coords\n",
    "\n",
    "# Use the 15 banking sentences from Part 3\n",
    "matrix = [list(map(float, v)) for v in sentence_vecs]\n",
    "coords = pca_2d(matrix)\n",
    "\n",
    "print(f\"‚úÖ PCA: 384 dimensions ‚Üí 2 dimensions for {len(matrix)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCII scatter plot ‚Äî cluster labels per sentence\n",
    "CLUSTER_MARKER = {\n",
    "    \"Compliance\": \"C\",\n",
    "    \"Fraud\":      \"F\",\n",
    "    \"Retail\":     \"R\",\n",
    "    \"Capital\":    \"K\",\n",
    "    \"Payments\":   \"P\",\n",
    "}\n",
    "\n",
    "xs = [c[0] for c in coords]\n",
    "ys = [c[1] for c in coords]\n",
    "x_min, x_max = min(xs), max(xs)\n",
    "y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "W, H = 70, 24\n",
    "grid = [[\" \"] * W for _ in range(H)]\n",
    "\n",
    "def to_grid(x, y):\n",
    "    col = int((x - x_min) / (x_max - x_min + 1e-9) * (W - 1))\n",
    "    row = int((1 - (y - y_min) / (y_max - y_min + 1e-9)) * (H - 1))\n",
    "    return max(0, min(W - 1, col)), max(0, min(H - 1, row))\n",
    "\n",
    "for label, (x, y) in zip(SENTENCE_LABELS, coords):\n",
    "    col, row = to_grid(x, y)\n",
    "    grid[row][col] = CLUSTER_MARKER[label]\n",
    "\n",
    "print(\"=== Banking Sentence Space ‚Äî 2D PCA (ASCII) ===\")\n",
    "print(\"C=Compliance  F=Fraud  R=Retail  K=Capital  P=Payments\")\n",
    "print()\n",
    "print(\"‚îå\" + \"‚îÄ\" * W + \"‚îê\")\n",
    "for row in grid:\n",
    "    print(\"‚îÇ\" + \"\".join(row) + \"‚îÇ\")\n",
    "print(\"‚îî\" + \"‚îÄ\" * W + \"‚îò\")\n",
    "print()\n",
    "print(\"üìå Each letter = one sentence. Same-cluster sentences should group together.\")\n",
    "print(\"   Unlike Notebook B (word vectors), these are SENTENCE vectors.\")\n",
    "print(\"   Full meaning encoded ‚Äî not just word averages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib scatter plot if available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    matplotlib.rcParams['figure.figsize'] = (13, 9)\n",
    "\n",
    "    cluster_colors = {\n",
    "        \"Compliance\": \"#e74c3c\",\n",
    "        \"Fraud\":      \"#8e44ad\",\n",
    "        \"Retail\":     \"#27ae60\",\n",
    "        \"Capital\":    \"#2980b9\",\n",
    "        \"Payments\":   \"#f39c12\",\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for sentence, label, (x, y) in zip(BANKING_SENTENCES, SENTENCE_LABELS, coords):\n",
    "        color = cluster_colors[label]\n",
    "        ax.scatter(x, y, color=color, s=150, zorder=2)\n",
    "        short = sentence[:40] + \"...\"\n",
    "        ax.annotate(short, (x, y), textcoords=\"offset points\",\n",
    "                    xytext=(6, 4), fontsize=7, color=color)\n",
    "\n",
    "    from matplotlib.patches import Patch\n",
    "    legend = [Patch(color=c, label=l) for l, c in cluster_colors.items()]\n",
    "    ax.legend(handles=legend, loc=\"best\", fontsize=10)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Banking Sentence Embeddings ‚Äî 2D PCA\\n\"\n",
    "        \"(all-MiniLM-L6-v2, 384 dims ‚Üí 2 dims)\",\n",
    "        fontsize=13\n",
    "    )\n",
    "    ax.set_xlabel(\"Principal Component 1\")\n",
    "    ax.set_ylabel(\"Principal Component 2\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"matplotlib not available ‚Äî ASCII plot above is the visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Inside the 384 Dimensions\n",
    "\n",
    "Same exploration as Notebook B ‚Äî but now with 384 dims and sentence vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all 384 dims for one sentence as a bar chart (every 8th dim for readability)\n",
    "def show_sentence_dims(sentence, stride=8):\n",
    "    \"\"\"Print dimension values for a sentence vector.\"\"\"\n",
    "    vec = list(model.encode(sentence))\n",
    "    vmax = max(abs(v) for v in vec)\n",
    "\n",
    "    print(f\"Sentence: '{sentence}'\")\n",
    "    print(f\"  Total dims: {len(vec)}  Range: [{min(vec):.4f}, {max(vec):.4f}]\")\n",
    "    print(f\"  Showing every {stride}th dimension:\")\n",
    "    print()\n",
    "    print(f\"  {'Dim':<7} {'Value':>9}  Bar\")\n",
    "    print(f\"  {'---':<7} {'-----':>9}  {'---'}\")\n",
    "\n",
    "    for i in range(0, len(vec), stride):\n",
    "        v = vec[i]\n",
    "        bar_len = int(abs(v) / (vmax + 1e-9) * 20)\n",
    "        bar = (\"‚ñà\" * bar_len) if v >= 0 else (\"‚ñí\" * bar_len)\n",
    "        sign = \"+\" if v >= 0 else \"-\"\n",
    "        print(f\"  dim{i:<4} {v:>9.4f}  {sign} {bar}\")\n",
    "\n",
    "show_sentence_dims(\"The AML team monitors suspicious transactions for money laundering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCII heatmap: 384 dims √ó 5 sentence clusters\n",
    "# Group sentences by cluster, take mean vector, render as shade\n",
    "\n",
    "SHADES = [\" \", \"¬∑\", \"‚ñë\", \"‚ñí\", \"‚ñì\", \"‚ñà\"]\n",
    "\n",
    "# Group sentence vectors by cluster\n",
    "cluster_vecs = {}\n",
    "for label, vec in zip(SENTENCE_LABELS, sentence_vecs):\n",
    "    cluster_vecs.setdefault(label, []).append(list(vec))\n",
    "\n",
    "# Mean vector per cluster\n",
    "cluster_means = {}\n",
    "for label, vecs in cluster_vecs.items():\n",
    "    n, d = len(vecs), len(vecs[0])\n",
    "    cluster_means[label] = [sum(v[i] for v in vecs) / n for i in range(d)]\n",
    "\n",
    "all_vals = [abs(v) for vec in cluster_means.values() for v in vec]\n",
    "vmax = max(all_vals)\n",
    "\n",
    "# Render heatmap ‚Äî show every 4th dim to fit the screen\n",
    "STRIDE = 4\n",
    "dim_count = len(next(iter(cluster_means.values())))\n",
    "shown_dims = list(range(0, dim_count, STRIDE))\n",
    "\n",
    "print(\"=== Dimension Heatmap: 384 Dims √ó 5 Clusters ===\")\n",
    "print(f\"(showing every {STRIDE}th dim ‚Äî {len(shown_dims)} columns)\")\n",
    "print(f\"Shade: ' '=~0  '¬∑'=small  '‚ñë‚ñí‚ñì‚ñà'=large\")\n",
    "print()\n",
    "\n",
    "# Column headers every 50 shown dims\n",
    "header = f\"  {'Cluster':<14}|\"\n",
    "for idx, d in enumerate(shown_dims):\n",
    "    if idx % 25 == 0:\n",
    "        header += str(d).ljust(25)\n",
    "print(header)\n",
    "print(\"  \" + \"-\" * (15 + len(shown_dims)))\n",
    "\n",
    "for cluster_name in [\"Compliance\", \"Fraud\", \"Retail\", \"Capital\", \"Payments\"]:\n",
    "    vec = cluster_means[cluster_name]\n",
    "    row = f\"  {cluster_name:<14}|\"\n",
    "    for d in shown_dims:\n",
    "        intensity = int(abs(vec[d]) / (vmax + 1e-9) * (len(SHADES) - 1))\n",
    "        row += SHADES[intensity]\n",
    "    print(row)\n",
    "\n",
    "print()\n",
    "print(\"üìå 384 dims = far more expressive than Notebook B's 50 dims.\")\n",
    "print(\"   The model distributes meaning across all 384 ‚Äî still no single dim = one concept.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most discriminating dims between two sentence clusters\n",
    "def most_discriminating_dims(cluster_a, cluster_b, cluster_means, top_n=10):\n",
    "    \"\"\"Find dimensions that differ most between two sentence clusters.\"\"\"\n",
    "    ma = cluster_means[cluster_a]\n",
    "    mb = cluster_means[cluster_b]\n",
    "    diffs = [(i, abs(ma[i] - mb[i]), ma[i], mb[i]) for i in range(len(ma))]\n",
    "    diffs.sort(key=lambda x: -x[1])\n",
    "\n",
    "    print(f\"Top {top_n} dims separating '{cluster_a}' from '{cluster_b}':\")\n",
    "    print(f\"  {'Dim':<7} {'|Diff|':>8}  {cluster_a:>13}  {cluster_b:>13}  Direction\")\n",
    "    print(\"  \" + \"-\" * 65)\n",
    "    for i, diff, va, vb in diffs[:top_n]:\n",
    "        higher = f\"‚Üê {cluster_a}\" if va > vb else f\"‚Üê {cluster_b}\"\n",
    "        print(f\"  dim{i:<4} {diff:>8.4f}  {va:>13.4f}  {vb:>13.4f}  {higher}\")\n",
    "\n",
    "most_discriminating_dims(\"Compliance\", \"Retail\", cluster_means)\n",
    "print()\n",
    "most_discriminating_dims(\"Fraud\", \"Payments\", cluster_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-part8-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Head-to-Head ‚Äî Notebook B vs Notebook A\n",
    "\n",
    "The definitive comparison: where Word2Vec (Notebook B) fails and sentence-transformers succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Paraphrase detection\n",
    "# Word2Vec: only works if exact same words appear in training corpus\n",
    "# sentence-transformers: understands paraphrase semantically\n",
    "\n",
    "paraphrase_pairs = [\n",
    "    (\n",
    "        \"The customer failed to provide identity documents for KYC.\",\n",
    "        \"The client did not submit identification for onboarding verification.\",\n",
    "        \"Paraphrase ‚Äî different words, same meaning\"\n",
    "    ),\n",
    "    (\n",
    "        \"Suspicious transaction flagged by AML system.\",\n",
    "        \"Anti-money laundering alert triggered on anomalous activity.\",\n",
    "        \"Paraphrase ‚Äî technical vs plain language\"\n",
    "    ),\n",
    "    (\n",
    "        \"The mortgage was rejected due to insufficient income.\",\n",
    "        \"Home loan application denied because earnings were too low.\",\n",
    "        \"Paraphrase ‚Äî formal vs informal phrasing\"\n",
    "    ),\n",
    "    (\n",
    "        \"AML compliance team monitors suspicious transactions daily.\",\n",
    "        \"Wire transfers above ten thousand dollars require reporting.\",\n",
    "        \"NOT a paraphrase ‚Äî different banking topics\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"=== Paraphrase Detection ===\")\n",
    "print()\n",
    "for s1, s2, label in paraphrase_pairs:\n",
    "    v1, v2 = model.encode(s1), model.encode(s2)\n",
    "    sim = cosine_sim(v1, v2)\n",
    "    verdict = \"‚úì PARAPHRASE\" if sim > 0.55 else \"‚úó DIFFERENT\"\n",
    "    print(f\"A: '{s1[:68]}'\")\n",
    "    print(f\"B: '{s2[:68]}'\")\n",
    "    print(f\"Similarity: {sim:.3f}  {verdict} ‚Äî {label}\")\n",
    "    print()\n",
    "\n",
    "print(\"üìå Word2Vec would score these based only on overlapping vocabulary.\")\n",
    "print(\"   'customer' ‚â† 'client' in Word2Vec unless both appeared in same sentences.\")\n",
    "print(\"   sentence-transformers understands synonyms because it was trained on them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Zero-shot ‚Äî sentences the model has never seen\n",
    "# Word2Vec (Notebook B) fails on out-of-vocabulary words\n",
    "# sentence-transformers handles unseen words via subword tokenization\n",
    "\n",
    "novel_sentences = [\n",
    "    \"The DORA regulation mandates ICT risk management for financial entities.\",  # new acronym\n",
    "    \"Stablecoin issuers must comply with MiCA capital reserve requirements.\",    # new domain\n",
    "    \"Embedded finance APIs now expose banking functions to non-bank fintechs.\",  # new jargon\n",
    "    \"AML red flags include structuring, layering, and integration of illicit funds.\",  # known domain\n",
    "]\n",
    "\n",
    "novel_vecs = model.encode(novel_sentences)\n",
    "\n",
    "print(\"=== Zero-Shot: Novel Banking Terminology ===\")\n",
    "print(\"(Testing sentences with terms the model may not have seen during training)\")\n",
    "print()\n",
    "\n",
    "# Compare new sentences to each other and to known sentences\n",
    "known_compliance = model.encode(\"AML compliance monitoring for suspicious transactions.\")\n",
    "\n",
    "for s, v in zip(novel_sentences, novel_vecs):\n",
    "    sim_to_known = cosine_sim(v, known_compliance)\n",
    "    print(f\"Sentence: '{s[:70]}'\")\n",
    "    print(f\"  Similarity to known compliance anchor: {sim_to_known:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"üìå Even for novel terms (DORA, MiCA, embedded finance):\")\n",
    "print(\"   The model produces valid 384-dim vectors ‚Äî no 'out of vocabulary' error.\")\n",
    "print(\"   Word2Vec (Notebook B) would return zero or skip unknown words entirely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Semantic search ‚Äî find the most relevant sentence for a query\n",
    "# This is the foundation of RAG (Session 3)\n",
    "\n",
    "def semantic_search(query, corpus, corpus_vecs, top_n=3):\n",
    "    \"\"\"Find top_n most similar sentences to query.\"\"\"\n",
    "    q_vec = model.encode(query)\n",
    "    scores = [(i, cosine_sim(q_vec, v)) for i, v in enumerate(corpus_vecs)]\n",
    "    scores.sort(key=lambda x: -x[1])\n",
    "    return [(corpus[i], s) for i, s in scores[:top_n]]\n",
    "\n",
    "queries = [\n",
    "    \"What controls prevent illicit financial flows?\",\n",
    "    \"How does a bank assess the risk of not being able to pay its debts?\",\n",
    "    \"International money movement between financial institutions\",\n",
    "]\n",
    "\n",
    "print(\"=== Semantic Search Over Banking Corpus ===\")\n",
    "print(\"(This is the retrieval step in RAG ‚Äî Session 3 will build the full pipeline)\")\n",
    "print()\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: '{query}'\")\n",
    "    results = semantic_search(query, BANKING_SENTENCES, sentence_vecs)\n",
    "    for rank, (sentence, score) in enumerate(results, 1):\n",
    "        print(f\"  {rank}. [{score:.3f}] {sentence}\")\n",
    "    print()\n",
    "\n",
    "print(\"üìå The query uses plain English ‚Äî no banking jargon required.\")\n",
    "print(\"   The model maps query and documents into the same 384-dim space.\")\n",
    "print(\"   Closest document vectors = most semantically relevant results.\")\n",
    "print(\"   In Session 3: this scales to thousands of documents using a vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary comparison table\n",
    "print(\"=== Notebook B vs Notebook A: Head-to-Head Results ===\")\n",
    "print()\n",
    "\n",
    "comparisons = [\n",
    "    (\"'bank' (financial) vs 'bank' (river)\",\n",
    "     \"IDENTICAL vector ‚Äî static\",\n",
    "     \"DIFFERENT vectors ‚Äî contextual\"),\n",
    "    (\"Paraphrase: 'customer' vs 'client'\",\n",
    "     \"Low sim ‚Äî both must be in corpus\",\n",
    "     \"High sim ‚Äî synonym understanding\"),\n",
    "    (\"Word order: 'A approved B' vs 'B approved A'\",\n",
    "     \"IDENTICAL ‚Äî averaging loses order\",\n",
    "     \"DIFFERENT ‚Äî transformer reads order\"),\n",
    "    (\"New acronym: DORA, MiCA\",\n",
    "     \"KeyError ‚Äî out of vocabulary\",\n",
    "     \"Valid vector ‚Äî subword tokenization\"),\n",
    "    (\"Semantic search on unseen query\",\n",
    "     \"Limited ‚Äî only corpus words match\",\n",
    "     \"Strong ‚Äî query mapped to same space\"),\n",
    "    (\"Training required\",\n",
    "     \"Yes ‚Äî you train it yourself\",\n",
    "     \"No ‚Äî pretrained on 1B+ pairs\"),\n",
    "    (\"Install size\",\n",
    "     \"~5MB\",\n",
    "     \"~500MB\"),\n",
    "    (\"Works behind proxy\",\n",
    "     \"Yes ‚Äî gensim only\",\n",
    "     \"Only after first download\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Test':<42} {'Notebook B (gensim)':<35} {'Notebook A (sentence-transformers)'}\")\n",
    "print(\"-\" * 120)\n",
    "for test, nb_b, nb_a in comparisons:\n",
    "    print(f\"{test:<42} {nb_b:<35} {nb_a}\")\n",
    "\n",
    "print()\n",
    "print(\"When to use which:\")\n",
    "print(\"  Notebook B (gensim): teach how embeddings work, air-gapped env, show training\")\n",
    "print(\"  Notebook A (this):   production similarity, paraphrase, semantic search, RAG prep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-exercise-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Hands-On Exercise: Explore Your Own Banking Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a banking domain and write 5 sentences for it\n",
    "# The model requires no training ‚Äî just encode and explore\n",
    "\n",
    "MY_DOMAIN = \"Your Domain Here\"\n",
    "\n",
    "MY_SENTENCES = [\n",
    "    # TODO: Write 5-8 realistic sentences from your chosen domain\n",
    "    \"First sentence about your domain topic here.\",\n",
    "    \"Second sentence with different wording about the same topic.\",\n",
    "    \"Third sentence that explores another aspect of your domain.\",\n",
    "    \"Fourth sentence ‚Äî try a paraphrase of sentence one.\",\n",
    "    \"Fifth sentence ‚Äî something clearly from a different topic.\",\n",
    "]\n",
    "\n",
    "# Encode your sentences\n",
    "my_vecs = model.encode(MY_SENTENCES)\n",
    "\n",
    "print(f\"Domain: {MY_DOMAIN}\")\n",
    "print(f\"Sentences: {len(MY_SENTENCES)}\")\n",
    "print(f\"Vector shape: {my_vecs.shape}\")\n",
    "print()\n",
    "\n",
    "# Similarity matrix\n",
    "print(\"Similarity matrix (row i vs column j):\")\n",
    "n = len(MY_SENTENCES)\n",
    "header = \" \" * 5 + \"\".join(f\"  S{j:<3}\" for j in range(n))\n",
    "print(header)\n",
    "for i in range(n):\n",
    "    row = f\"S{i:<3} \"\n",
    "    for j in range(n):\n",
    "        sim = cosine_sim(my_vecs[i], my_vecs[j])\n",
    "        row += f\"  {sim:.2f}\"\n",
    "    print(row)\n",
    "\n",
    "print()\n",
    "print(\"Questions to discuss:\")\n",
    "print(\"  1. Which pairs scored highest? Are they genuine paraphrases?\")\n",
    "print(\"  2. Which pairs scored lowest? Do they cover distinct subtopics?\")\n",
    "print(\"  3. Try a QUERY sentence (not in MY_SENTENCES) ‚Äî run semantic_search on it.\")\n",
    "print(\"  4. What bias might exist in your sentences?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: What You Experienced\n",
    "\n",
    "| Part | Concept | Key Takeaway |\n",
    "|------|---------|-------------|\n",
    "| 1. Model | Pretrained transformer | 22M params, trained on 1B+ pairs ‚Äî already knows English |\n",
    "| 2. Word-level | Single-word vectors | Model understands AML‚âàKYC without your corpus |\n",
    "| 3. Sentence-level | Full context encoding | Word order, grammar, intent all encoded |\n",
    "| 4. Context | 'bank' disambiguation | Different vector per sentence ‚Äî the core innovation |\n",
    "| 5. Bias | Pretrained bias | Internet-scale training ‚Üí internet-scale biases |\n",
    "| 6. Visualize | 2D PCA of sentences | Sentence clusters emerge ‚Äî not word clusters |\n",
    "| 7. Dimensions | Inside 384 dims | Same principle as 50 dims ‚Äî pattern, not labels |\n",
    "| 8. Comparison | B vs A head-to-head | Each wins in different scenarios |\n",
    "\n",
    "### The Natural Next Step ‚Äî Session 3\n",
    "\n",
    "```\n",
    "You just did:  sentence ‚Üí 384-dim vector ‚Üí cosine similarity\n",
    "\n",
    "Session 3 adds:\n",
    "  1. A corpus of thousands of banking documents (PDFs, regulations, reports)\n",
    "  2. A vector database (ChromaDB / pgvector) storing all their embeddings\n",
    "  3. A query comes in ‚Üí embed it ‚Üí find top-K similar document chunks\n",
    "  4. Pass those chunks + query to an LLM ‚Üí grounded, cited answer\n",
    "\n",
    "That is RAG: Retrieval-Augmented Generation.\n",
    "The embedding model you used today (all-MiniLM-L6-v2) is the retrieval engine.\n",
    "```"
   ]
  }
 ]
}
