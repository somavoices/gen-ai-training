{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: AI/GenAI Fundamentals â€” Interactive Demos\n",
    "\n",
    "**Audience:** Banking Technologists  \n",
    "**Duration:** Run cells live during training (~45 min of demos)  \n",
    "\n",
    "---\n",
    "\n",
    "## Setup â€” Run This First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install -q tiktoken gensim scikit-learn numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import textwrap, random, time, json\n",
    "\n",
    "print(\"All imports ready! Let's explore AI fundamentals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: How Machines Understand Words â€” Embeddings\n",
    "\n",
    "Before LLMs can predict the next token, they need to **convert words into numbers**.  \n",
    "These numbers are called **embeddings** â€” vectors that capture *meaning*.\n",
    "\n",
    "The famous result: **King - Man + Woman = Queen**  \n",
    "Let's see if it actually works â€” and what it reveals about bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading Pre-Trained Word Embeddings\n",
    "\n",
    "We'll use **GloVe** (Global Vectors) â€” trained on billions of words from the internet.  \n",
    "Same concept as the embedding layer inside ChatGPT/Claude, just smaller and inspectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "print(\"Downloading GloVe embeddings (50-dimensional, ~66MB)...\")\n",
    "print(\"This captures meaning of 400,000 words in 50 numbers each.\\n\")\n",
    "\n",
    "glove = api.load('glove-wiki-gigaword-50')\n",
    "\n",
    "print(f\"Loaded! Vocabulary size: {len(glove):,} words\")\n",
    "print(f\"Each word â†’ vector of {glove.vector_size} numbers\")\n",
    "print(f\"\\nExample â€” the word 'bank' as numbers:\")\n",
    "print(f\"  {glove['bank'][:10]}...  (showing first 10 of 50 dimensions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 The Classic: King - Man + Woman = ?\n",
    "\n",
    "If embeddings truly capture meaning, then **arithmetic on word vectors** should work:\n",
    "\n",
    "```\n",
    "King  is to  Man\n",
    "  as\n",
    "  ?   is to  Woman\n",
    "```\n",
    "\n",
    "Mathematically: `vector(King) - vector(Man) + vector(Woman) = vector(?)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def word_algebra(positive, negative, topn=5):\n    \"\"\"Perform word vector arithmetic and show results.\"\"\"\n    # Build readable expression\n    pos_str = \" + \".join(positive)\n    neg_str = \" - \".join(negative)\n    expression = f\"{pos_str} - {neg_str}\"\n    \n    print(f\"  Given: {expression} = ?\\n\")\n    \n    results = glove.most_similar(positive=positive, negative=negative, topn=topn)\n    \n    print(f\"  {'Rank':<6} {'Word':<20} {'Similarity':>10}\")\n    print(f\"  {'â”€'*6} {'â”€'*20} {'â”€'*10}\")\n    for i, (word, score) in enumerate(results, 1):\n        marker = \" â—„\" if i == 1 else \"\"\n        print(f\"  {i:<6} {word:<20} {score:>10.4f}{marker}\")\n    return results\n\nprint(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\nprint(\"  THE CLASSIC: King - Man + Woman = ?\")\nprint(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n\nresults = word_algebra(['king', 'woman'], ['man'])\n\nprint(f\"\\n  âœ… Top result: '{results[0][0]}' â€” It works!\")\nprint(f\"  The model learned that King:Man :: Queen:Woman\")\nprint(f\"  ...just from reading billions of words. No one told it about royalty.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 More Fun Analogies â€” Banking & Beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "analogies = [\n    {\n        \"name\": \"ğŸŒ Country-Capital\",\n        \"question\": \"Paris is to France as ? is to Germany\",\n        \"calc\": \"paris + germany - france\",\n        \"positive\": [\"paris\", \"germany\"],\n        \"negative\": [\"france\"],\n        \"expected\": \"berlin\"\n    },\n    {\n        \"name\": \"ğŸ’° Currency\",\n        \"question\": \"Dollar is to USA as ? is to Japan\",\n        \"calc\": \"dollar + japan - usa\",\n        \"positive\": [\"dollar\", \"japan\"],\n        \"negative\": [\"usa\"],\n        \"expected\": \"yen\"\n    },\n    {\n        \"name\": \"ğŸ“ Comparative\",\n        \"question\": \"Big is to Bigger as ? relates to Small\",\n        \"calc\": \"bigger + small - big\",\n        \"positive\": [\"bigger\", \"small\"],\n        \"negative\": [\"big\"],\n        \"expected\": \"smaller\"\n    },\n    {\n        \"name\": \"ğŸ¢ CEO Analogy\",\n        \"question\": \"Jobs is to Apple as ? is to Microsoft\",\n        \"calc\": \"jobs + microsoft - apple\",\n        \"positive\": [\"jobs\", \"microsoft\"],\n        \"negative\": [\"apple\"],\n        \"expected\": \"gates\"\n    },\n    {\n        \"name\": \"â° Tense\",\n        \"question\": \"Walking is to Walked as Swimming is to ?\",\n        \"calc\": \"swimming + walked - walking\",\n        \"positive\": [\"swimming\", \"walked\"],\n        \"negative\": [\"walking\"],\n        \"expected\": \"swam\"\n    },\n    {\n        \"name\": \"ğŸ¦ Banking Context\",\n        \"question\": \"Credit is to Debit as Deposit is to ?\",\n        \"calc\": \"deposit + debit - credit\",\n        \"positive\": [\"deposit\", \"debit\"],\n        \"negative\": [\"credit\"],\n        \"expected\": \"withdrawal\"\n    },\n]\n\nfor a in analogies:\n    print(f\"\\n{'â”€'*60}\")\n    print(f\"  {a['name']}\")\n    print(f\"  Q: {a['question']}\")\n    print(f\"  Given: {a['calc']}\")\n    print(f\"  Expected: {a['expected']}\")\n    print()\n    try:\n        results = glove.most_similar(positive=a['positive'], negative=a['negative'], topn=3)\n        for i, (word, score) in enumerate(results, 1):\n            marker = \" âœ…\" if word == a['expected'] else \"\"\n            print(f\"    {i}. {word:<18} (similarity: {score:.4f}){marker}\")\n        \n        if results[0][0] == a['expected']:\n            print(f\"  â†’ Nailed it!\")\n        elif a['expected'] in [r[0] for r in results]:\n            print(f\"  â†’ Close! Expected word is in top 3\")\n        else:\n            print(f\"  â†’ Interesting â€” model learned a different association\")\n    except KeyError as e:\n        print(f\"    Word not in vocabulary: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 âš ï¸ The Dark Side: Bias in Embeddings\n",
    "\n",
    "Here's where it gets serious for banking.  \n",
    "If embeddings learn meaning from text... **they also learn stereotypes**.\n",
    "\n",
    "Let's look at what happens with **profession + gender** arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\nprint(\"  âš ï¸  BIAS IN WORD EMBEDDINGS: Modern Jobs & Gender\")\nprint(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\nprint()\nprint(\"  Question: What does the model associate with each gender\")\nprint(\"  when we combine profession words with gender words?\")\nprint()\n\nprofessions = ['doctor', 'nurse', 'programmer', 'teacher', \n               'engineer', 'secretary', 'scientist', 'receptionist',\n               'banker', 'manager', 'ceo', 'assistant']\n\nprint(f\"  {'Profession':<16} {'Expression':<30} {'Result':<18} {'Bias?'}\")\nprint(f\"  {'â”€'*16} {'â”€'*30} {'â”€'*18} {'â”€'*8}\")\n\nfor prof in professions:\n    try:\n        # profession + woman - man\n        female_assoc = glove.most_similar(positive=[prof, 'woman'], negative=['man'], topn=1)[0]\n        # profession + man - woman  \n        male_assoc = glove.most_similar(positive=[prof, 'man'], negative=['woman'], topn=1)[0]\n        \n        # Flag obvious stereotypes\n        stereotypical_female = ['nurse', 'secretary', 'receptionist', 'assistant',\n                                'mother', 'wife', 'girl', 'she', 'her', 'feminine',\n                                'midwife', 'waitress', 'maid', 'nanny', 'housekeeper']\n        stereotypical_male = ['surgeon', 'programmer', 'boss', 'executive', 'chief',\n                             'he', 'his', 'father', 'himself', 'man', 'masculine',\n                             'ceo', 'businessman', 'developer']\n        \n        # Show female association\n        expr_f = f\"{prof} + woman - man\"\n        bias_f = \"âš ï¸ Yes\" if female_assoc[0] in stereotypical_female else \"\"\n        print(f\"  {prof:<16} {expr_f:<30} {female_assoc[0]:<18} {bias_f}\")\n        \n        # Show male association\n        expr_m = f\"{prof} + man - woman\"\n        bias_m = \"âš ï¸ Yes\" if male_assoc[0] in stereotypical_male else \"\"\n        print(f\"  {'':<16} {expr_m:<30} {male_assoc[0]:<18} {bias_m}\")\n        print()\n        \n    except KeyError:\n        print(f\"  {prof:<16} (not in vocabulary)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\nprint(\"  ğŸ”¬ DEEP DIVE: The 'Funny' but Serious Examples\")\nprint(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n\nprint(\"  Case 1: What is the 'female version' of a programmer?\\n\")\nresults = word_algebra(['programmer', 'woman'], ['man'], topn=10)\nprint(f\"\\n  Top result: '{results[0][0]}' â€” Notice the gender stereotype!\")\n\nprint(\"\\n  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\nprint(\"\\n  Case 2: What is the 'male version' of a nurse?\\n\")\nresults2 = word_algebra(['nurse', 'man'], ['woman'], topn=10)\nprint(f\"\\n  Top result: '{results2[0][0]}' â€” Again, stereotype reinforced!\")\n\nprint(\"\\n  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\nprint(\"\\n  Case 3: Modern tech jobs and gender bias\\n\")\nprint(\"  Given: developer + woman - man = ?\\n\")\ntry:\n    results3 = glove.most_similar(positive=['developer', 'woman'], negative=['man'], topn=5)\n    print(f\"  {'Rank':<6} {'Word':<20} {'Similarity':>10}\")\n    print(f\"  {'â”€'*6} {'â”€'*20} {'â”€'*10}\")\n    for i, (word, score) in enumerate(results3, 1):\n        print(f\"  {i:<6} {word:<20} {score:>10.4f}\")\nexcept KeyError:\n    print(\"  (developer not in this vocabulary)\")\n\nprint(\"\\n  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\nprint(\"\\n  Case 4: What about 'CEO'?\\n\")\nresults4 = word_algebra(['ceo', 'woman'], ['man'], topn=5)\n\nprint(\"\\n\" + \"â”€\"*60)\nprint(\"  ğŸ¦ WHY THIS MATTERS FOR BANKING:\")\nprint(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\nprint(\"  â€¢ Credit models using embeddings inherit these biases\")\nprint(\"  â€¢ Customer service bots may respond differently by name\")\nprint(\"  â€¢ Resume screening tools penalized female candidates (Amazon 2018)\")\nprint(\"  â€¢ LLMs built on these embeddings carry the same biases forward\")\nprint(\"  â€¢ ECOA and Fair Lending laws make this a LEGAL risk, not just ethical\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸŒ BONUS BIAS: Nationality + Finance\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "\n",
    "print(\"  What words does the model associate with different countries + money?\\n\")\n",
    "\n",
    "countries = ['american', 'chinese', 'indian', 'nigerian', 'german', 'mexican', 'russian']\n",
    "\n",
    "for country in countries:\n",
    "    try:\n",
    "        results = glove.most_similar(positive=[country, 'money'], topn=5)\n",
    "        words = [r[0] for r in results]\n",
    "        print(f\"  {country:<12} + money â†’ {', '.join(words[:5])}\")\n",
    "    except KeyError:\n",
    "        print(f\"  {country:<12} (not in vocabulary)\")\n",
    "\n",
    "print(\"\\n  âš ï¸  Notice any patterns? The model may associate some nationalities\")\n",
    "print(\"  with wealth and others with poverty â€” based purely on training text.\")\n",
    "print(\"  In banking, this could bias: fraud scoring, credit decisions, KYC risk ratings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Word Similarity â€” What the Model Thinks Is \"Close\"\n",
    "\n",
    "Before we leave embeddings, let's see which words the model considers most similar to banking terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_words = ['mortgage', 'fraud', 'compliance', 'trading', 'risk', \n",
    "                 'loan', 'bitcoin', 'recession', 'bailout', 'audit']\n",
    "\n",
    "print(\"What words live 'near' banking terms in embedding space?\\n\")\n",
    "print(f\"  {'Word':<14} {'Nearest Neighbors (by cosine similarity)'}\")\n",
    "print(f\"  {'â”€'*14} {'â”€'*50}\")\n",
    "\n",
    "for word in banking_words:\n",
    "    try:\n",
    "        neighbors = glove.most_similar(word, topn=6)\n",
    "        neighbor_str = ', '.join([f\"{w} ({s:.2f})\" for w, s in neighbors])\n",
    "        print(f\"  {word:<14} {neighbor_str}\")\n",
    "    except KeyError:\n",
    "        print(f\"  {word:<14} (not in vocabulary)\")\n",
    "\n",
    "print(f\"\\n  ğŸ’¡ This is how LLMs 'understand' context.\")\n",
    "print(f\"  Words that appear in similar contexts end up close in vector space.\")\n",
    "print(f\"  'fraud' is near 'corruption' and 'scandal' â€” because they co-occur in text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Tokenization â€” How LLMs Break Down Text\n",
    "\n",
    "LLMs don't read words â€” they read **tokens** (subword units).  \n",
    "This affects **cost**, **context limits**, and some surprising behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")  # Used by GPT-4 / similar to Claude\n",
    "\n",
    "def show_tokens(text, label=\"\"):\n",
    "    \"\"\"Visualize how text gets tokenized, with color-like alternating display.\"\"\"\n",
    "    tokens = enc.encode(text)\n",
    "    decoded = [enc.decode([t]) for t in tokens]\n",
    "    \n",
    "    if label:\n",
    "        print(f\"\\n  ğŸ“ {label}\")\n",
    "    print(f\"  Input:  \\\"{text}\\\"\")\n",
    "    print(f\"  Tokens: {len(tokens)} (chars/token: {len(text)/len(tokens):.1f})\")\n",
    "    \n",
    "    # Show tokens with alternating markers for visibility\n",
    "    display = \"\"\n",
    "    for i, t in enumerate(decoded):\n",
    "        marker = 'â”‚' if i % 2 == 0 else 'â”Š'\n",
    "        display += f\"{marker}{t}\"\n",
    "    print(f\"  Split:  {display}â”‚\")\n",
    "    return tokens\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  TOKENIZATION: How LLMs See Your Text\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "show_tokens(\"Hello, how can I help you today?\", \"Simple greeting\")\n",
    "show_tokens(\"Account balance: $45,231.67\", \"Account balance\")\n",
    "show_tokens(\"NullPointerException at AccountService.java:142\", \"Java error\")\n",
    "show_tokens(\"SELECT * FROM transactions WHERE amount > 10000;\", \"SQL query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 ğŸ¤¯ Surprising Tokenization: Numbers, Emojis, and Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ¤¯ TOKENIZATION SURPRISES\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "# Numbers are weird\n",
    "print(\"\\nâ”€â”€ Numbers: Not What You'd Expect â”€â”€\")\n",
    "show_tokens(\"1000\", \"One thousand\")\n",
    "show_tokens(\"10000\", \"Ten thousand\")\n",
    "show_tokens(\"100000\", \"Hundred thousand\")\n",
    "show_tokens(\"$9,999.99\", \"Just under 10K (CTR threshold!)\")\n",
    "show_tokens(\"$10,000.00\", \"Exactly 10K\")\n",
    "print(\"\\n  ğŸ’¡ Numbers get split into chunks! This is why LLMs struggle with math.\")\n",
    "print(\"  The model doesn't see '10000' as a number â€” it sees separate token pieces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emojis are expensive!\n",
    "print(\"\\nâ”€â”€ Emojis: Surprisingly Expensive â”€â”€\")\n",
    "show_tokens(\"Transaction approved\", \"Plain text\")\n",
    "show_tokens(\"Transaction approved âœ…\", \"With one emoji\")\n",
    "show_tokens(\"âœ… âŒ âš ï¸ ğŸ¦ ğŸ’° ğŸ“Š\", \"Just 6 emojis\")\n",
    "show_tokens(\"ğŸ¦ğŸ’°ğŸ“ŠğŸ”’ğŸš¨ğŸ“‹\", \"6 emojis no spaces\")\n",
    "print(\"\\n  ğŸ’¡ Each emoji costs 1-3 tokens! In customer-facing chatbots,\")\n",
    "print(\"  emoji-heavy messages can double your token costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Languages: Non-English costs more\n",
    "print(\"\\nâ”€â”€ Languages: The Multilingual Tax â”€â”€\")\n",
    "sentences = [\n",
    "    (\"English\",  \"Please transfer $500 to account 4821.\"),\n",
    "    (\"Spanish\",  \"Por favor transfiera $500 a la cuenta 4821.\"),\n",
    "    (\"Japanese\", \"å£åº§4821ã«500ãƒ‰ãƒ«ã‚’é€é‡‘ã—ã¦ãã ã•ã„ã€‚\"),\n",
    "    (\"Arabic\",   \"ÙŠØ±Ø¬Ù‰ ØªØ­ÙˆÙŠÙ„ 500 Ø¯ÙˆÙ„Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø³Ø§Ø¨ 4821.\"),\n",
    "    (\"Hindi\",    \"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤–à¤¾à¤¤à¤¾ 4821 à¤®à¥‡à¤‚ $500 à¤¸à¥à¤¥à¤¾à¤¨à¤¾à¤‚à¤¤à¤°à¤¿à¤¤ à¤•à¤°à¥‡à¤‚à¥¤\"),\n",
    "    (\"Korean\",   \"ê³„ì¢Œ 4821ë¡œ 500ë‹¬ëŸ¬ë¥¼ ì´ì²´í•´ ì£¼ì„¸ìš”.\"),\n",
    "]\n",
    "\n",
    "print(f\"  Same banking instruction in different languages:\\n\")\n",
    "print(f\"  {'Language':<12} {'Tokens':>8} {'Chars':>8} {'Chars/Token':>12} {'Cost Ratio':>12}\")\n",
    "print(f\"  {'â”€'*12} {'â”€'*8} {'â”€'*8} {'â”€'*12} {'â”€'*12}\")\n",
    "\n",
    "english_tokens = len(enc.encode(sentences[0][1]))\n",
    "for lang, text in sentences:\n",
    "    tokens = enc.encode(text)\n",
    "    ratio = len(tokens) / english_tokens\n",
    "    print(f\"  {lang:<12} {len(tokens):>8} {len(text):>8} {len(text)/len(tokens):>12.1f} {ratio:>11.1f}x\")\n",
    "\n",
    "print(f\"\\n  ğŸ’¡ Non-English text can cost 2-4x MORE tokens!\")\n",
    "print(f\"  For global banks serving customers in multiple languages,\")\n",
    "print(f\"  this dramatically affects API costs and context window usage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaces and formatting matter\n",
    "print(\"\\nâ”€â”€ Whitespace & Formatting: Hidden Costs â”€â”€\")\n",
    "show_tokens(\"name,amount,date\", \"CSV (compact)\")\n",
    "show_tokens(\"name, amount, date\", \"CSV (with spaces)\")\n",
    "show_tokens('{\"name\": \"John\", \"amount\": 500}', \"JSON\")\n",
    "show_tokens(\"name: John\\namount: 500\", \"YAML-style\")\n",
    "show_tokens(\"    if amount > 10000:\", \"Python with indent\")\n",
    "show_tokens(\"if amount > 10000:\", \"Python without indent\")\n",
    "\n",
    "print(\"\\n  ğŸ’¡ Indentation, spaces, and formatting all cost tokens.\")\n",
    "print(\"  Minified code/data uses fewer tokens but is harder for the model to read.\")\n",
    "print(\"  TRADEOFF: readability vs. token efficiency (covered more in Session 4).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Banking Document Token Costs\n",
    "\n",
    "How many tokens do real banking documents use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic banking document sizes\n",
    "documents = [\n",
    "    (\"Customer complaint email\", 200, 0),\n",
    "    (\"Call center transcript (15 min)\", 3000, 0),\n",
    "    (\"Mortgage application (50 pages)\", 20000, 0),\n",
    "    (\"Quarterly earnings report\", 30000, 0),\n",
    "    (\"SAR narrative\", 800, 0),\n",
    "    (\"OCC Bulletin (30 pages)\", 12000, 0),\n",
    "    (\"Basel III final rule (1,089 pages)\", 400000, 0),\n",
    "    (\"Medium Java codebase (50 files)\", 100000, 0),\n",
    "    (\"Terraform module (500 lines)\", 3500, 0),\n",
    "    (\"Incident postmortem\", 2000, 0),\n",
    "]\n",
    "\n",
    "CONTEXT_WINDOW = 200_000\n",
    "\n",
    "# Claude pricing\n",
    "PRICING = {\n",
    "    'Haiku':  {'input': 0.25,  'output': 1.25},\n",
    "    'Sonnet': {'input': 3.00,  'output': 15.00},\n",
    "    'Opus':   {'input': 15.00, 'output': 75.00},\n",
    "}\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ“„ Banking Document Token Costs\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "\n",
    "# Approximate words per token = 0.75\n",
    "data = []\n",
    "for doc_name, word_count, _ in documents:\n",
    "    tokens = int(word_count / 0.75)\n",
    "    pct_window = tokens / CONTEXT_WINDOW * 100\n",
    "    fits = \"âœ…\" if tokens <= CONTEXT_WINDOW else \"âŒ\"\n",
    "    sonnet_cost = tokens * PRICING['Sonnet']['input'] / 1_000_000\n",
    "    data.append({\n",
    "        'Document': doc_name,\n",
    "        'Words': f\"{word_count:,}\",\n",
    "        'Tokens': f\"{tokens:,}\",\n",
    "        '% of 200K': f\"{pct_window:.1f}%\",\n",
    "        'Fits?': fits,\n",
    "        'Sonnet Input $': f\"${sonnet_cost:.4f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n  ğŸ’¡ Most banking documents fit easily in Claude's 200K context window.\")\n",
    "print(f\"  Basel III is the exception â€” too large for a single request.\")\n",
    "print(f\"  Solution: chunking and RAG (covered in Session 3).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Discriminative vs. Generative Models\n",
    "\n",
    "- **Discriminative** = Classifier (sorts things into buckets)  \n",
    "- **Generative** = Writer (creates new content)  \n",
    "\n",
    "Let's build both for the same banking problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Discriminative Model: Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ” DISCRIMINATIVE MODEL: Fraud Detection Classifier\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"\\n  Building a model that CLASSIFIES transactions as fraud/not-fraud.\")\n",
    "print(\"  This is what runs in your bank RIGHT NOW.\\n\")\n",
    "\n",
    "# Generate synthetic data\n",
    "n_legit, n_fraud = 9500, 500\n",
    "\n",
    "legit = np.column_stack([\n",
    "    np.random.lognormal(3.5, 1.2, n_legit),          # amount\n",
    "    np.random.choice(range(8, 22), n_legit),           # hour (daytime)\n",
    "    np.random.choice([0, 1], n_legit, p=[0.9, 0.1]),  # international\n",
    "    np.random.uniform(0, 0.3, n_legit),                # merchant risk\n",
    "    np.random.poisson(2, n_legit),                     # velocity\n",
    "])\n",
    "\n",
    "fraud = np.column_stack([\n",
    "    np.random.lognormal(5.5, 1.5, n_fraud),           # higher amounts\n",
    "    np.random.choice(range(0, 24), n_fraud),            # any hour\n",
    "    np.random.choice([0, 1], n_fraud, p=[0.4, 0.6]),   # more international\n",
    "    np.random.uniform(0.5, 1.0, n_fraud),              # high merchant risk\n",
    "    np.random.poisson(8, n_fraud),                      # high velocity\n",
    "])\n",
    "\n",
    "X = np.vstack([legit, fraud])\n",
    "y = np.array([0]*n_legit + [1]*n_fraud)\n",
    "features = ['amount', 'hour', 'is_intl', 'merchant_risk', 'velocity_1hr']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(f\"  AUC-ROC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(f\"\\n  Feature Importance (what the model learned):\")\n",
    "for name, imp in sorted(zip(features, model.feature_importances_), key=lambda x: -x[1]):\n",
    "    bar = 'â–ˆ' * int(imp * 40)\n",
    "    print(f\"    {name:<18} {imp:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score real-looking transactions\n",
    "print(\"\\n  â”€â”€ Scoring Example Transactions â”€â”€\\n\")\n",
    "\n",
    "test_txns = [\n",
    "    {\"desc\": \"â˜• Coffee shop, 2pm, domestic\",         \"data\": [4.50, 14, 0, 0.05, 1]},\n",
    "    {\"desc\": \"ğŸ›ï¸ Online shopping, 8pm, domestic\",     \"data\": [127.00, 20, 0, 0.15, 2]},\n",
    "    {\"desc\": \"ğŸŒ™ Electronics, 2am, international\",    \"data\": [2847.00, 2, 1, 0.75, 6]},\n",
    "    {\"desc\": \"ğŸš¨ Jewelry, 3am, intl, high velocity\",  \"data\": [8900.00, 3, 1, 0.92, 15]},\n",
    "    {\"desc\": \"ğŸ¦ Wire transfer, 10am, domestic\",      \"data\": [15000.00, 10, 0, 0.20, 1]},\n",
    "]\n",
    "\n",
    "for txn in test_txns:\n",
    "    prob = model.predict_proba([txn['data']])[0][1]\n",
    "    decision = \"ğŸš« BLOCK\" if prob > 0.5 else \"âœ… ALLOW\"\n",
    "    bar = 'â–ˆ' * int(prob * 30) + 'â–‘' * (30 - int(prob * 30))\n",
    "    print(f\"  {txn['desc']}\")\n",
    "    print(f\"    ${txn['data'][0]:>10,.2f} â†’ fraud: {prob:.4f} [{bar}] {decision}\")\n",
    "    print()\n",
    "\n",
    "print(\"  KEY: Discriminative model outputs a NUMBER (probability).\")\n",
    "print(\"       It CANNOT explain WHY. It CANNOT write a report.\")\n",
    "print(\"       That's where generative models come in â†“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generative Model Simulation: Next-Token Prediction\n",
    "\n",
    "We can't run Claude in a notebook without an API key, so here's a **Markov chain** that demonstrates the *same principle* (next-token prediction) at a tiny scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  âœï¸ GENERATIVE MODEL: Next-Token Prediction\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "# Mini \"training corpus\" â€” banking text\n",
    "corpus = \"\"\"\n",
    "The customer account balance is currently below the minimum threshold.\n",
    "The customer account was flagged for suspicious activity last month.\n",
    "The customer requested a wire transfer to an international account.\n",
    "The transaction was declined due to insufficient funds in the account.\n",
    "The transaction amount exceeds the daily withdrawal limit set by policy.\n",
    "The transaction was flagged by our fraud detection system for review.\n",
    "The compliance team reviewed the suspicious activity report carefully.\n",
    "The compliance team approved the wire transfer after full verification.\n",
    "The risk assessment indicates elevated exposure in the current portfolio.\n",
    "The risk assessment was completed per regulatory requirements today.\n",
    "The regulatory filing deadline is approaching for quarterly reports.\n",
    "The regulatory update requires changes to our KYC procedures immediately.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Build bigram model\n",
    "words = corpus.split()\n",
    "bigrams = {}\n",
    "for i in range(len(words) - 1):\n",
    "    key = words[i].lower()\n",
    "    bigrams.setdefault(key, []).append(words[i + 1])\n",
    "\n",
    "# Show probabilities for \"the\" â†’ next word\n",
    "print(\"\\n  After seeing the word 'the', what comes next?\\n\")\n",
    "\n",
    "next_words = bigrams.get('the', [])\n",
    "counts = Counter(next_words)\n",
    "total = len(next_words)\n",
    "\n",
    "print(f\"  {'Next Token':<20} {'Count':>6} {'Probability':>12} {'Distribution'}\")\n",
    "print(f\"  {'â”€'*20} {'â”€'*6} {'â”€'*12} {'â”€'*30}\")\n",
    "for word, count in counts.most_common():\n",
    "    prob = count / total\n",
    "    bar = 'â–ˆ' * int(prob * 30)\n",
    "    print(f\"  {word:<20} {count:>6} {prob:>11.1%} {bar}\")\n",
    "\n",
    "print(f\"\\n  Real LLMs do the SAME THING but with:\")\n",
    "print(f\"  â€¢ 200,000 tokens of context (not just 1 prior word)\")\n",
    "print(f\"  â€¢ Trillions of training tokens (not 12 sentences)\")\n",
    "print(f\"  â€¢ 100+ billion parameters (not a simple count table)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature comparison\n",
    "print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸŒ¡ï¸ TEMPERATURE: Controlling Randomness\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "\n",
    "def generate_text(seed, length=10, temperature=1.0):\n",
    "    result = [seed]\n",
    "    current = seed.lower()\n",
    "    for _ in range(length):\n",
    "        if current not in bigrams:\n",
    "            break\n",
    "        candidates = bigrams[current]\n",
    "        counts = Counter(candidates)\n",
    "        words_list = list(counts.keys())\n",
    "        probs = [counts[w] for w in words_list]\n",
    "        probs = [p ** (1.0 / max(temperature, 0.01)) for p in probs]\n",
    "        total = sum(probs)\n",
    "        probs = [p / total for p in probs]\n",
    "        chosen = random.choices(words_list, weights=probs, k=1)[0]\n",
    "        result.append(chosen)\n",
    "        current = chosen.lower().rstrip('.')\n",
    "    return ' '.join(result)\n",
    "\n",
    "for temp in [0.01, 0.5, 1.0, 2.0]:\n",
    "    print(f\"  Temperature = {temp}:\")\n",
    "    random.seed(42)\n",
    "    for i in range(3):\n",
    "        text = generate_text(\"The\", length=10, temperature=temp)\n",
    "        print(f\"    â†’ {text}\")\n",
    "    print()\n",
    "\n",
    "print(\"  Banking guidance:\")\n",
    "print(\"    Compliance/regulatory â†’ LOW temp (0.0-0.3): deterministic, factual\")\n",
    "print(\"    Code generation       â†’ LOW-MED (0.0-0.5): correct, consistent\")\n",
    "print(\"    Drafting emails       â†’ MEDIUM (0.5-0.7): natural, varied\")\n",
    "print(\"    Brainstorming         â†’ HIGHER (0.7-1.0): creative, diverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: The Four Eras â€” Same Problem, Different Approaches\n",
    "\n",
    "Let's see how each AI era would handle the **same suspicious transaction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ¦ ONE TRANSACTION, FOUR ERAS OF AI\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "txn = {\n",
    "    'customer': 'Quickship Logistics LLC',\n",
    "    'account': '****9912',\n",
    "    'amount': 9450.00,\n",
    "    'type': 'cash_deposit',\n",
    "    'branch': 'Branch #127, Miami FL',\n",
    "    'daily_total': 28350.00,\n",
    "    'pattern': '5 deposits in 5 days at 5 different branches, all $9,390-$9,510',\n",
    "}\n",
    "\n",
    "print(f\"\\n  Transaction: {txn['customer']}\")\n",
    "print(f\"  Amount: ${txn['amount']:,.2f} | Type: {txn['type']} | Branch: {txn['branch']}\")\n",
    "print(f\"  Daily total: ${txn['daily_total']:,.2f}\")\n",
    "print(f\"  Pattern: {txn['pattern']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA 1: Rule-Based\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚  ERA 1: RULE-BASED (1980s)                              â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "flags = []\n",
    "if 8000 < txn['amount'] < 10000:\n",
    "    flags.append(\"STRUCTURING: Amount between $8K-$10K (below CTR threshold)\")\n",
    "if txn['daily_total'] > 25000:\n",
    "    flags.append(\"VELOCITY: Daily cash total exceeds $25K\")\n",
    "\n",
    "print(f\"\\n  Rules checked: 2\")\n",
    "print(f\"  Code:  IF amount BETWEEN 8000 AND 10000 THEN flag\")\n",
    "print(f\"         IF daily_cash_total > 25000 THEN flag\")\n",
    "print(f\"\\n  Results:\")\n",
    "for f in flags:\n",
    "    print(f\"    âš ï¸  {f}\")\n",
    "print(f\"\\n  Output: {'FLAG' if flags else 'PASS'} (binary decision, no explanation)\")\n",
    "print(f\"  Time: <1ms | Cost: $0 | Explainability: âœ… Perfect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA 2: Machine Learning\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚  ERA 2: MACHINE LEARNING (2000s)                        â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "ml_features = {\n",
    "    'amount_to_threshold_ratio': 9450 / 10000,\n",
    "    'daily_total_ratio': 28350 / 50000,\n",
    "    'is_cash': 1.0,\n",
    "    'branch_diversity_7d': 5 / 5,  # 5 unique branches in 5 days\n",
    "    'amount_std_dev': 48.0,  # very consistent amounts\n",
    "}\n",
    "\n",
    "print(f\"\\n  Features extracted:\")\n",
    "for k, v in ml_features.items():\n",
    "    print(f\"    {k:<30} = {v:.3f}\")\n",
    "\n",
    "# Simulated weighted score\n",
    "score = 0.945 * 0.30 + 0.567 * 0.20 + 1.0 * 0.15 + 1.0 * 0.25 + (1 - 48/500) * 0.10\n",
    "print(f\"\\n  Suspicion score: {score:.4f}\")\n",
    "bar = 'â–ˆ' * int(score * 40) + 'â–‘' * (40 - int(score * 40))\n",
    "print(f\"  [{bar}]\")\n",
    "print(f\"\\n  Output: SCORE = {score:.4f} (probability, no explanation)\")\n",
    "print(f\"  Time: ~5ms | Cost: $0 | Explainability: âš ï¸ Feature importance only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA 3: Deep Learning\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚  ERA 3: DEEP LEARNING (2010s)                           â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(f\"\\n  LSTM analyzes the SEQUENCE of recent transactions:\")\n",
    "print(f\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(f\"  â”‚ Date     â”‚ Amount    â”‚ Type         â”‚ Branch   â”‚\")\n",
    "print(f\"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "print(f\"  â”‚ Dec 10   â”‚ $9,420    â”‚ Cash deposit â”‚ #103     â”‚\")\n",
    "print(f\"  â”‚ Dec 11   â”‚ $9,480    â”‚ Cash deposit â”‚ #115     â”‚\")\n",
    "print(f\"  â”‚ Dec 13   â”‚ $9,390    â”‚ Cash deposit â”‚ #108     â”‚\")\n",
    "print(f\"  â”‚ Dec 14   â”‚ $9,510    â”‚ Cash deposit â”‚ #121     â”‚\")\n",
    "print(f\"  â”‚ Dec 15   â”‚ $9,450    â”‚ Cash deposit â”‚ #127  â—„  â”‚\")\n",
    "print(f\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print(f\"\")\n",
    "print(f\"  Patterns detected by sequence model:\")\n",
    "print(f\"    â€¢ Consistent sub-$10K amounts (structuring signature)\")\n",
    "print(f\"    â€¢ Different branches each day (geographic dispersion)\")\n",
    "print(f\"    â€¢ Daily cadence (velocity anomaly)\")\n",
    "print(f\"\\n  Sequence score: 0.94 (very high confidence)\")\n",
    "print(f\"\\n  Output: SCORE = 0.94 (pattern-aware, still no text explanation)\")\n",
    "print(f\"  Time: ~20ms | Cost: $0 | Explainability: âŒ Black box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA 4: Generative AI\n",
    "print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"â”‚  ERA 4: GENERATIVE AI (2020s)                           â”‚\")\n",
    "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "print(f\"\\n  Input: All data above + prompt: 'Draft SAR narrative'\")\n",
    "print(f\"\")\n",
    "print(f\"  Generated Output:\")\n",
    "print(f\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(f\"  â”‚ SUSPICIOUS ACTIVITY ANALYSIS                                â”‚\")\n",
    "print(f\"  â”‚                                                              â”‚\")\n",
    "print(f\"  â”‚ Subject: Quickship Logistics LLC (Acct ****9912)             â”‚\")\n",
    "print(f\"  â”‚ Period: December 10-15, 2024                                 â”‚\")\n",
    "print(f\"  â”‚                                                              â”‚\")\n",
    "print(f\"  â”‚ FINDINGS:                                                    â”‚\")\n",
    "print(f\"  â”‚ The Subject made 5 cash deposits over 5 consecutive          â”‚\")\n",
    "print(f\"  â”‚ business days totaling $47,250, with individual deposits     â”‚\")\n",
    "print(f\"  â”‚ ranging from $9,390 to $9,510 â€” all below the $10,000       â”‚\")\n",
    "print(f\"  â”‚ CTR reporting threshold.                                     â”‚\")\n",
    "print(f\"  â”‚                                                              â”‚\")\n",
    "print(f\"  â”‚ INDICATORS:                                                  â”‚\")\n",
    "print(f\"  â”‚ 1. Structuring (31 CFR 1010.311): Sub-$10K pattern           â”‚\")\n",
    "print(f\"  â”‚ 2. Geographic dispersion: 5 branches in 5 days               â”‚\")\n",
    "print(f\"  â”‚ 3. Volume anomaly: 3.2x above monthly average                â”‚\")\n",
    "print(f\"  â”‚                                                              â”‚\")\n",
    "print(f\"  â”‚ RECOMMENDATION: Escalate to BSA team for SAR filing.         â”‚\")\n",
    "print(f\"  â”‚ Refs: 31 USC 5324, 31 CFR 1010.311                          â”‚\")\n",
    "print(f\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print(f\"\")\n",
    "print(f\"  Output: FULL NARRATIVE with citations, ready for analyst review\")\n",
    "print(f\"  Time: ~3s | Cost: ~$0.02 | Explainability: âœ… Natural language\")\n",
    "\n",
    "print(f\"\\n  âš ï¸ BUT: Citations could be hallucinated! Always verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison table\n",
    "print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ“Š COMPARISON: Same Transaction, Four Approaches\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {'Era': 'Rule-Based', 'Output': 'Binary flag', 'Latency': '<1ms', 'Cost': '$0',\n",
    "     'Explainability': 'âœ… Perfect', 'Catches This?': 'âœ… Yes (threshold)'},\n",
    "    {'Era': 'ML', 'Output': 'Score (0-1)', 'Latency': '~5ms', 'Cost': '$0',\n",
    "     'Explainability': 'âš ï¸ Limited', 'Catches This?': 'âœ… Yes (features)'},\n",
    "    {'Era': 'Deep Learning', 'Output': 'Score (sequence)', 'Latency': '~20ms', 'Cost': '$0',\n",
    "     'Explainability': 'âŒ Black box', 'Catches This?': 'âœ… Yes (pattern)'},\n",
    "    {'Era': 'GenAI', 'Output': 'Full narrative', 'Latency': '~3s', 'Cost': '~$0.02',\n",
    "     'Explainability': 'âœ… Natural language', 'Catches This?': 'âœ… + explains why'},\n",
    "])\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "print(f\"\\n  KEY INSIGHT: Each era ADDS capability. Best practice: use ALL FOUR together.\")\n",
    "print(f\"  Rules detect â†’ ML scores â†’ DL finds patterns â†’ GenAI explains & drafts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Fun But Important â€” Things That Trip Up LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 ğŸ§® LLMs Can't Do Math (Reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ§® FUN BUT IMPORTANT: Why LLMs Struggle with Math\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print(\"  LLMs predict tokens, not compute arithmetic.\")\n",
    "print(\"  Let's see why this matters for banking...\\n\")\n",
    "\n",
    "# Show how numbers get tokenized â€” they're not \"numbers\" to the model\n",
    "calculations = [\n",
    "    (\"Simple\", \"47 + 38\", 85),\n",
    "    (\"Medium\", \"1,247 Ã— 3\", 3741),\n",
    "    (\"Banking\", \"$45,231.67 + $12,847.33\", 58079.00),\n",
    "    (\"APR\", \"($15,000 Ã— 0.065) / 12\", 81.25),\n",
    "    (\"Large\", \"8,347,291 + 4,158,632\", 12505923),\n",
    "]\n",
    "\n",
    "print(f\"  How the model 'sees' numbers vs. how we see them:\\n\")\n",
    "\n",
    "for label, expr, answer in calculations:\n",
    "    tokens = enc.encode(expr)\n",
    "    decoded = [enc.decode([t]) for t in tokens]\n",
    "    print(f\"  {label}: {expr} = {answer:,}\")\n",
    "    print(f\"    Model sees: {decoded}  ({len(tokens)} tokens)\")\n",
    "    print(f\"    The model must PREDICT the answer token-by-token,\")\n",
    "    print(f\"    not CALCULATE it. It's pattern matching, not arithmetic.\\n\")\n",
    "\n",
    "print(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"  ğŸ¦ BANKING RULE: Never trust LLM math directly.\")\n",
    "print(\"     â€¢ Ask it to WRITE the calculation code\")\n",
    "print(\"     â€¢ Run the code yourself\")\n",
    "print(\"     â€¢ Especially for: APR, IRR, amortization, P&L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 ğŸ”„ The Reversal Curse â€” LLMs Have One-Way Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ”„ THE REVERSAL CURSE\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print('  LLMs trained on \"A is B\" often CANNOT answer \"B is ?\"')\n",
    "print()\n",
    "print(\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"  â”‚ Training data says:                                  â”‚\")\n",
    "print('  â”‚   \"The CEO of JPMorgan Chase is Jamie Dimon\"         â”‚')\n",
    "print(\"  â”‚                                                      â”‚\")\n",
    "print(\"  â”‚ Q: Who is the CEO of JPMorgan Chase?                 â”‚\")\n",
    "print(\"  â”‚ A: Jamie Dimon  âœ…  (forward direction, easy)        â”‚\")\n",
    "print(\"  â”‚                                                      â”‚\")\n",
    "print(\"  â”‚ Q: Jamie Dimon is the CEO of which company?          â”‚\")\n",
    "print(\"  â”‚ A: Might struggle!  âš ï¸  (reverse direction, harder)  â”‚\")\n",
    "print(\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print()\n",
    "print(\"  Why? Because the model learned to predict tokens LEFT â†’ RIGHT.\")\n",
    "print('  \"CEO of JPMorgan\" â†’ predicts â†’ \"Jamie Dimon\"')\n",
    "print('  \"Jamie Dimon\" â†’ doesn\\'t as strongly predict â†’ \"JPMorgan\"')\n",
    "print()\n",
    "print(\"  ğŸ¦ Banking implications:\")\n",
    "print('  â€¢ \"What regulation covers wire transfers?\" â†’ Good')\n",
    "print('  â€¢ \"What does Reg E cover?\" â†’ Also good (common in training data)')\n",
    "print('  â€¢ \"Who is the BSA officer at our bank?\" â†’ Unknown (not in training)')\n",
    "print('  â€¢ \"Which accounts does customer #4821 have?\" â†’ Cannot know')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 ğŸ­ Prompt Framing: The Model Follows Your Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ­ PROMPT FRAMING BIAS\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print(\"  The same transaction gets DIFFERENT analyses depending\")\n",
    "print(\"  on how you frame the prompt.\\n\")\n",
    "\n",
    "print(\"  Transaction: $9,450 cash deposit at Branch #127\\n\")\n",
    "\n",
    "print(\"  â”Œâ”€ PROMPT A (Biased: assumes guilt) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"  â”‚ 'This transaction looks suspicious. Explain why this       â”‚\")\n",
    "print(\"  â”‚  customer is likely structuring deposits to avoid CTR.'    â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â”‚ â†’ Model will AGREE and build a case for structuring.       â”‚\")\n",
    "print(\"  â”‚   It follows your framing.                                 â”‚\")\n",
    "print(\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print()\n",
    "print(\"  â”Œâ”€ PROMPT B (Neutral: asks for analysis) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"  â”‚ 'Analyze this transaction objectively. Identify patterns   â”‚\")\n",
    "print(\"  â”‚  that could indicate suspicious activity AND patterns      â”‚\")\n",
    "print(\"  â”‚  that suggest legitimate business operations.'             â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â”‚ â†’ Model will present BOTH sides.                           â”‚\")\n",
    "print(\"  â”‚   Balanced analysis with evidence for and against.          â”‚\")\n",
    "print(\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print()\n",
    "print(\"  â”Œâ”€ PROMPT C (Biased: assumes innocence) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"  â”‚ 'This is a legitimate freight broker. Explain why their    â”‚\")\n",
    "print(\"  â”‚  cash deposits are normal business activity.'              â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â”‚ â†’ Model will AGREE and rationalize the deposits.           â”‚\")\n",
    "print(\"  â”‚   It follows your framing.                                 â”‚\")\n",
    "print(\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print()\n",
    "print(\"  âš ï¸  BANKING RULE: Always use NEUTRAL prompts for compliance.\")\n",
    "print(\"  The model is a mirror â€” it reflects the bias you put in.\")\n",
    "print(\"  This is especially dangerous for: SAR reviews, credit decisions,\")\n",
    "print(\"  customer complaint analysis, and any regulatory work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 ğŸ”¢ Counting & Precision â€” Not the Model's Strong Suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ”¢ COUNTING & PRECISION FAILURES\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "\n",
    "# Count letters in a word â€” LLMs are famously bad at this\n",
    "test_words = [\n",
    "    (\"strawberry\", 'r'),\n",
    "    (\"mississippi\", 's'),\n",
    "    (\"accommodation\", 'c'),\n",
    "    (\"assessment\", 's'),\n",
    "]\n",
    "\n",
    "print(\"  How many times does a letter appear? (Famously hard for LLMs)\\n\")\n",
    "for word, letter in test_words:\n",
    "    correct = word.count(letter)\n",
    "    print(f\"  How many '{letter}'s in '{word}'?\")\n",
    "    print(f\"    Correct answer: {correct}\")\n",
    "    tokens = enc.encode(word)\n",
    "    decoded = [enc.decode([t]) for t in tokens]\n",
    "    print(f\"    Model sees tokens: {decoded}  (NOT individual letters!)\")\n",
    "    print()\n",
    "\n",
    "print(\"  Why? The model sees TOKENS, not individual characters.\")\n",
    "print(\"  'strawberry' â†’ ['str', 'aw', 'berry']  â€” the 'r's are SPLIT across tokens!\")\n",
    "print()\n",
    "print(\"  ğŸ¦ Banking implication:\")\n",
    "print(\"  â€¢ Don't ask LLMs to COUNT transactions in a dataset\")\n",
    "print(\"  â€¢ Don't ask LLMs for EXACT numerical summaries\")\n",
    "print(\"  â€¢ DO ask LLMs to WRITE the SQL/Python that counts for you\")\n",
    "print(\"  â€¢ DO ask LLMs to EXPLAIN patterns you've already quantified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 ğŸ’¸ Float vs. Decimal â€” Why Banking Code Must Use BigDecimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ’¸ THE FLOATING POINT TRAP (Not GenAI â€” But LLMs Generate This Bug!)\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print(\"  If you ask an LLM to write banking code, it might use float.\")\n",
    "print(\"  Here's why that's DANGEROUS:\\n\")\n",
    "\n",
    "# Classic floating point problem\n",
    "print(\"  Using float (WRONG for banking):\")\n",
    "a = 0.1 + 0.2\n",
    "print(f\"    0.1 + 0.2 = {a}\")\n",
    "print(f\"    0.1 + 0.2 == 0.3?  {a == 0.3}  ğŸ˜±\\n\")\n",
    "\n",
    "# Compound the error across transactions\n",
    "print(\"  Compounding error across 10,000 transactions:\")\n",
    "balance_float = 0.0\n",
    "balance_decimal = Decimal('0.00')\n",
    "\n",
    "for i in range(10000):\n",
    "    balance_float += 0.01\n",
    "    balance_decimal += Decimal('0.01')\n",
    "\n",
    "print(f\"    float result:   ${balance_float:.10f}  (should be $100.00)\")\n",
    "print(f\"    Decimal result: ${balance_decimal}\")\n",
    "print(f\"    Error: ${abs(100.0 - balance_float):.10f}\")\n",
    "print()\n",
    "\n",
    "# At banking scale\n",
    "print(\"  At banking scale (1M transactions/day):\")\n",
    "daily_error = abs(100.0 - balance_float) * 100  # scale up\n",
    "yearly_error = daily_error * 365\n",
    "print(f\"    Potential daily rounding error: ${daily_error:.4f}\")\n",
    "print(f\"    Potential yearly error: ${yearly_error:.2f}\")\n",
    "print(f\"    Over 10 years: ${yearly_error * 10:,.2f}\")\n",
    "print()\n",
    "print(\"  âš ï¸ When LLMs generate banking code, ALWAYS check for float/double.\")\n",
    "print(\"  CLAUDE.md rule: 'All monetary amounts use BigDecimal, never float/double'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Bias Deep Dive â€” Training Data Reflects History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  âš–ï¸ BIAS IN LENDING: How Historical Discrimination Propagates\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print(\"  We'll train a model on HISTORICAL lending data.\")\n",
    "print(\"  The data reflects past discrimination: Group B was denied\")\n",
    "print(\"  more often EVEN with similar credit profiles.\\n\")\n",
    "\n",
    "# Generate data with historical bias\n",
    "n = 1000\n",
    "\n",
    "# Group A: historically favored\n",
    "income_a = np.random.normal(75000, 20000, n)\n",
    "score_a = np.random.normal(720, 50, n)\n",
    "dti_a = np.random.normal(0.32, 0.08, n)\n",
    "# Higher base approval rate (historical privilege)\n",
    "prob_a = np.clip(0.75 + (score_a - 700)/1000 + (income_a - 60000)/500000 - dti_a, 0.1, 0.95)\n",
    "approved_a = (np.random.random(n) < prob_a).astype(int)\n",
    "\n",
    "# Group B: historically disadvantaged (SIMILAR profiles, LOWER approval)\n",
    "income_b = np.random.normal(70000, 22000, n)\n",
    "score_b = np.random.normal(710, 55, n)\n",
    "dti_b = np.random.normal(0.34, 0.09, n)\n",
    "# Lower base approval rate (historical discrimination)\n",
    "prob_b = np.clip(0.55 + (score_b - 700)/1000 + (income_b - 60000)/500000 - dti_b, 0.1, 0.95)\n",
    "approved_b = (np.random.random(n) < prob_b).astype(int)\n",
    "\n",
    "print(\"  Historical Data:\")\n",
    "print(f\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(f\"  â”‚ Group      â”‚ Avg Income   â”‚ Avg Score    â”‚ Avg DTI      â”‚ Approval Rate  â”‚\")\n",
    "print(f\"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "print(f\"  â”‚ Group A    â”‚ ${income_a.mean():>9,.0f}  â”‚ {score_a.mean():>10.0f}  â”‚ {dti_a.mean():>10.2f}  â”‚ {approved_a.mean():>12.1%}  â”‚\")\n",
    "print(f\"  â”‚ Group B    â”‚ ${income_b.mean():>9,.0f}  â”‚ {score_b.mean():>10.0f}  â”‚ {dti_b.mean():>10.2f}  â”‚ {approved_b.mean():>12.1%}  â”‚\")\n",
    "print(f\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print(f\"\\n  âš ï¸ Similar profiles, but {approved_a.mean() - approved_b.mean():.0%} gap in approval rates!\")\n",
    "print(f\"  This gap = historical discrimination baked into the training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on biased data (model never sees group label)\n",
    "X = np.vstack([\n",
    "    np.column_stack([income_a, score_a, dti_a]),\n",
    "    np.column_stack([income_b, score_b, dti_b])\n",
    "])\n",
    "y = np.concatenate([approved_a, approved_b])\n",
    "\n",
    "model_biased = LogisticRegression(random_state=42)\n",
    "model_biased.fit(X, y)\n",
    "\n",
    "# Score both groups\n",
    "preds_a = model_biased.predict_proba(np.column_stack([income_a, score_a, dti_a]))[:, 1]\n",
    "preds_b = model_biased.predict_proba(np.column_stack([income_b, score_b, dti_b]))[:, 1]\n",
    "\n",
    "print(\"\\n  Model trained on biased data (group label NOT given to model):\")\n",
    "print(f\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(f\"  â”‚ Group      â”‚ Avg Predicted Approval    â”‚\")\n",
    "print(f\"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "print(f\"  â”‚ Group A    â”‚ {preds_a.mean():>22.1%}  â”‚\")\n",
    "print(f\"  â”‚ Group B    â”‚ {preds_b.mean():>22.1%}  â”‚\")\n",
    "print(f\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "print(f\"\\n  Model-predicted gap: {preds_a.mean() - preds_b.mean():.1%}\")\n",
    "print(f\"\\n  â†’ The model LEARNED the bias even though it never saw the group label.\")\n",
    "print(f\"  â†’ It found proxies in the data (slight income/score/DTI differences)\")\n",
    "print(f\"    and amplified them to match the biased historical outcomes.\")\n",
    "print(f\"\\n  This is EXACTLY how discrimination propagates through AI systems.\")\n",
    "print(f\"  ECOA + Fair Lending laws require disparate impact testing for this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Spot the Hallucination â€” Interactive Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ” SPOT THE HALLUCINATION: Banking Edition\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print()\n",
    "print(\"  Below is an AI-generated response about Reg E.\")\n",
    "print(\"  Some parts are accurate. Some are HALLUCINATED.\")\n",
    "print(\"  Can you spot which is which?\\n\")\n",
    "\n",
    "print(\"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"  â”‚  AI RESPONSE:                                             â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â”‚  Under Regulation E (12 CFR 1005.11), the financial       â”‚\")\n",
    "print(\"  â”‚  institution must:                                         â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â”‚  1. Investigate within 10 business days               [?] â”‚\")\n",
    "print(\"  â”‚  2. Provisionally credit within 10 business days if   [?] â”‚\")\n",
    "print(\"  â”‚     more time needed                                      â”‚\")\n",
    "print(\"  â”‚  3. Complete investigation within 45 calendar days    [?] â”‚\")\n",
    "print(\"  â”‚  4. For new accounts: 90 calendar days allowed        [?] â”‚\")\n",
    "print(\"  â”‚  5. Report results within 3 business days             [?] â”‚\")\n",
    "print(\"  â”‚  6. Per Section 1005.11(d)(2), reverse provisional    [?] â”‚\")\n",
    "print(\"  â”‚     credit only after 5 business days' written notice     â”‚\")\n",
    "print(\"  â”‚  7. Institutions with <$50M assets are exempt per     [?] â”‚\")\n",
    "print(\"  â”‚     the 2019 EFTA amendment                               â”‚\")\n",
    "print(\"  â”‚                                                            â”‚\")\n",
    "print(\"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reveal answers\n",
    "print(\"\\n  â”€â”€ ANSWERS â”€â”€\\n\")\n",
    "\n",
    "items = [\n",
    "    (\"1\", \"10 business day investigation\", \"âœ… ACCURATE\", \"Standard Reg E timeline\"),\n",
    "    (\"2\", \"Provisional credit in 10 days\", \"âœ… ACCURATE\", \"Required if investigation extends\"),\n",
    "    (\"3\", \"45 calendar day completion\", \"âœ… ACCURATE\", \"Standard completion deadline\"),\n",
    "    (\"4\", \"90 days for new accounts\", \"âœ… ACCURATE\", \"Applies to new accounts, POS, international\"),\n",
    "    (\"5\", \"3 business days to report\", \"âš ï¸ VERIFY\", \"Commonly cited but exact number should be checked against regulation text\"),\n",
    "    (\"6\", \"Section 1005.11(d)(2)\", \"âš ï¸ LIKELY HALLUCINATED\", \"Specific subsection citation may be fabricated. The concept exists but the exact citation needs verification.\"),\n",
    "    (\"7\", \"$50M asset exemption\", \"âŒ HALLUCINATED\", \"There is NO such exemption in Reg E. This was completely invented by the model. This is the DANGEROUS kind.\"),\n",
    "]\n",
    "\n",
    "for num, claim, status, explanation in items:\n",
    "    print(f\"  {status}  Item {num}: {claim}\")\n",
    "    print(f\"         {explanation}\\n\")\n",
    "\n",
    "print(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"  KEY LESSON: The most dangerous hallucinations LOOK real.\")\n",
    "print(\"  Item 7 is completely invented but reads like a real exemption.\")\n",
    "print(\"  In banking, acting on a hallucinated regulation = compliance violation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 8: Token Cost Calculator â€” Interactive\n",
    "\n",
    "Calculate costs for your own banking workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICING = {\n",
    "    'Haiku':  {'input': 0.25,  'output': 1.25},\n",
    "    'Sonnet': {'input': 3.00,  'output': 15.00},\n",
    "    'Opus':   {'input': 15.00, 'output': 75.00},\n",
    "}\n",
    "\n",
    "tasks = [\n",
    "    {\"name\": \"Summarize 10-page loan doc\",        \"in\": 4000,    \"out\": 500,   \"model\": \"Sonnet\", \"vol\": 200},\n",
    "    {\"name\": \"Generate unit tests (Java class)\",   \"in\": 2000,    \"out\": 3000,  \"model\": \"Sonnet\", \"vol\": 50},\n",
    "    {\"name\": \"Analyze 200-page regulation\",        \"in\": 80000,   \"out\": 2000,  \"model\": \"Opus\",   \"vol\": 5},\n",
    "    {\"name\": \"Classify customer email\",             \"in\": 270,     \"out\": 10,    \"model\": \"Haiku\",  \"vol\": 10000},\n",
    "    {\"name\": \"Draft SAR narrative\",                 \"in\": 5000,    \"out\": 3000,  \"model\": \"Sonnet\", \"vol\": 100},\n",
    "    {\"name\": \"Generate Terraform module\",           \"in\": 500,     \"out\": 2000,  \"model\": \"Sonnet\", \"vol\": 10},\n",
    "    {\"name\": \"Code review (500 lines)\",             \"in\": 3000,    \"out\": 1000,  \"model\": \"Sonnet\", \"vol\": 30},\n",
    "    {\"name\": \"Incident postmortem draft\",           \"in\": 3000,    \"out\": 2500,  \"model\": \"Sonnet\", \"vol\": 3},\n",
    "]\n",
    "\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"  ğŸ’° TOKEN ECONOMICS: Full Cost Analysis for Banking Workloads\")\n",
    "print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "\n",
    "rows = []\n",
    "total_daily = 0\n",
    "for t in tasks:\n",
    "    p = PRICING[t['model']]\n",
    "    per_call = t['in'] * p['input'] / 1e6 + t['out'] * p['output'] / 1e6\n",
    "    daily = per_call * t['vol']\n",
    "    total_daily += daily\n",
    "    rows.append({\n",
    "        'Task': t['name'],\n",
    "        'Model': t['model'],\n",
    "        'In Tokens': f\"{t['in']:,}\",\n",
    "        'Out Tokens': f\"{t['out']:,}\",\n",
    "        'Per Call': f\"${per_call:.4f}\",\n",
    "        'Daily Vol': f\"{t['vol']:,}\",\n",
    "        'Daily Cost': f\"${daily:.2f}\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n  {'â”€'*60}\")\n",
    "print(f\"  Total Daily Cost:    ${total_daily:>10.2f}\")\n",
    "print(f\"  Monthly (22 days):   ${total_daily * 22:>10.2f}\")\n",
    "print(f\"  Annual (260 days):   ${total_daily * 260:>10,.2f}\")\n",
    "\n",
    "print(f\"\\n  Compare: One compliance analyst salary = ~$80,000-120,000/year\")\n",
    "print(f\"  AI API costs for the above workload   = ~${total_daily * 260:,.0f}/year\")\n",
    "print(f\"  (Plus human review time â€” AI assists, doesn't replace)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 9: Live Claude API Call (Optional)\n",
    "\n",
    "If you have an `ANTHROPIC_API_KEY`, run this cell to see a real API call in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and set your API key to run this cell\n",
    "# import os\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'sk-ant-...'\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    import os\n",
    "    \n",
    "    api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "    if not api_key:\n",
    "        print(\"Set ANTHROPIC_API_KEY to run this demo.\")\n",
    "        print(\"Uncomment the os.environ line above and paste your key.\")\n",
    "    else:\n",
    "        client = anthropic.Anthropic(api_key=api_key)\n",
    "        \n",
    "        prompt = \"\"\"You are a banking compliance assistant. A customer made 5 cash \n",
    "deposits of ~$9,450 each at 5 different branches in 5 days. The customer runs \n",
    "a small freight brokerage with $200K annual revenue. Provide a brief (100 word) \n",
    "risk assessment with regulatory references.\"\"\"\n",
    "        \n",
    "        print(\"Sending to Claude Haiku...\\n\")\n",
    "        start = time.time()\n",
    "        \n",
    "        msg = client.messages.create(\n",
    "            model=\"claude-haiku-4-5-20251001\",\n",
    "            max_tokens=300,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        print(f\"Response ({elapsed:.2f}s, {msg.usage.input_tokens} in / {msg.usage.output_tokens} out):\\n\")\n",
    "        print(msg.content[0].text)\n",
    "        \n",
    "        cost = msg.usage.input_tokens * 0.25/1e6 + msg.usage.output_tokens * 1.25/1e6\n",
    "        print(f\"\\nCost: ${cost:.6f}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Install anthropic: pip install anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary: What We Demonstrated\n",
    "\n",
    "| Demo | Key Takeaway |\n",
    "|------|-------------|\n",
    "| **Word Embeddings** | Words become numbers. Arithmetic works (King-Man+Woman=Queen). But embeddings also encode societal **biases**. |\n",
    "| **Gender + Profession** | Programmer-Man+Woman reveals stereotypes. These biases flow into LLMs. Critical for Fair Lending. |\n",
    "| **Tokenization** | LLMs see tokens, not words. Emojis are expensive. Non-English costs 2-4x more. Numbers get split. |\n",
    "| **Four Eras** | Rule-based â†’ ML â†’ DL â†’ GenAI. Each adds capability. Banks use all four. |\n",
    "| **Discriminative vs Generative** | Classifier outputs a score. Generator outputs text. Modern systems use both. |\n",
    "| **LLMs Can't Do Math** | Token prediction â‰  calculation. Always verify. Ask it to write code, not compute. |\n",
    "| **Reversal Curse** | Models learn Aâ†’B better than Bâ†’A. Don't assume bidirectional knowledge. |\n",
    "| **Prompt Framing** | The model mirrors your bias. Use neutral prompts for compliance. |\n",
    "| **Floating Point** | LLMs may generate float-based banking code. Always enforce BigDecimal. |\n",
    "| **Historical Bias in Lending** | Models learn discrimination from biased data, even without protected class features. |\n",
    "| **Spot the Hallucination** | Fabricated regulatory citations look real. Always verify against source documents. |\n",
    "| **Token Economics** | Individual calls are cheap. Scale matters. Still far cheaper than manual labor. |\n",
    "\n",
    "---\n",
    "\n",
    "**Next Session:** GenAI vs Agentic AI â€” From answering questions to taking actions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}